{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKyEOXjWJK6V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/train.csv')\n",
        "test_df = pd.read_csv('/content/test.csv')\n",
        "\n",
        "combined_df = pd.concat([train_df.drop('Survived', axis=1), test_df], axis=0)\n",
        "combined_df = combined_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "XzcamX3gJNYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df['Title'] = combined_df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "combined_df['Title'] = combined_df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "combined_df['Title'] = combined_df['Title'].replace('Mlle', 'Miss')\n",
        "combined_df['Title'] = combined_df['Title'].replace('Ms', 'Miss')\n",
        "combined_df['Title'] = combined_df['Title'].replace('Mme', 'Mrs')\n",
        "\n",
        "\n",
        "numerical_features = ['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']\n",
        "categorical_features = ['Sex', 'Embarked', 'Title']\n",
        "\n",
        "\n",
        "numerical_imputer = SimpleImputer(strategy='median')\n",
        "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "combined_df[numerical_features] = numerical_imputer.fit_transform(combined_df[numerical_features])\n",
        "combined_df[categorical_features] = categorical_imputer.fit_transform(combined_df[categorical_features])\n",
        "\n",
        "\n",
        "combined_df = pd.get_dummies(combined_df, columns=categorical_features, drop_first=True)\n",
        "\n",
        "features_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
        "combined_df = combined_df.drop(features_to_drop, axis=1)\n",
        "combined_df = combined_df.drop('PassengerId', axis=1, errors='ignore')"
      ],
      "metadata": {
        "id": "9ZbA-V8BJP2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = combined_df[:len(train_df)]\n",
        "y = train_df['Survived'].values\n",
        "\n",
        "\n",
        "X = X.select_dtypes(include=np.number)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "y_val = torch.tensor(y_val, dtype=torch.float32).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "2UZJJEE2JSjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TitanicClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2):\n",
        "        super(TitanicClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc3 = nn.Linear(hidden_size2, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.sigmoid(x)\n",
        "        # Ensure the output is within the range [0, 1] by adding a small epsilon\n",
        "        #x = torch.clamp(x, 1e-7, 1 - 1e-7)  # Commenting out the clamp function\n",
        "        return x"
      ],
      "metadata": {
        "id": "xpqWPAXyJVD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train.shape[1]\n",
        "hidden_size1 = 64\n",
        "hidden_size2 = 32\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100\n",
        "batch_size = 32\n"
      ],
      "metadata": {
        "id": "RNzpoSATJXzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TitanicClassifier(input_size, hidden_size1, hidden_size2)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 2)\n",
        "\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "JoM7psnIJY1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_val)\n",
        "        val_loss = criterion(val_outputs, y_val)\n",
        "        val_predictions = (val_outputs > 0.5).float()\n",
        "        val_accuracy = accuracy_score(y_val.cpu().numpy(), val_predictions.cpu().numpy())\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Loss: {val_loss.item():.4f}, Validation Accuracy: {val_accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INHZIRS9Ja9T",
        "outputId": "00b9732d-052a-4dae-d527-71f1ef203ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 50.0000, Validation Loss: 37.4302, Validation Accuracy: 0.6257\n",
            "Epoch [2/100], Loss: 50.0000, Validation Loss: 36.8717, Validation Accuracy: 0.6313\n",
            "Epoch [3/100], Loss: 75.0000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [4/100], Loss: 25.0000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [5/100], Loss: 50.0000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [6/100], Loss: 62.5000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [7/100], Loss: 50.0000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [8/100], Loss: 50.0000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [9/100], Loss: 50.0000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [10/100], Loss: 37.5000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [11/100], Loss: 37.5000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [12/100], Loss: 50.0000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [13/100], Loss: 50.0000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [14/100], Loss: 37.5000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [15/100], Loss: 62.5000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [16/100], Loss: 25.0000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [17/100], Loss: 12.5000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [18/100], Loss: 50.0000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [19/100], Loss: 75.0000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [20/100], Loss: 37.5000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [21/100], Loss: 62.5000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [22/100], Loss: 50.0000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [23/100], Loss: 50.0000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [24/100], Loss: 62.5000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [25/100], Loss: 50.0000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [26/100], Loss: 50.0000, Validation Loss: 37.9888, Validation Accuracy: 0.6201\n",
            "Epoch [27/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [28/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [29/100], Loss: 12.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [30/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [31/100], Loss: 25.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [32/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [33/100], Loss: 87.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [34/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [35/100], Loss: 25.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [36/100], Loss: 12.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [37/100], Loss: 62.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [38/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [39/100], Loss: 62.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [40/100], Loss: 25.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [41/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [42/100], Loss: 25.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [43/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [44/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [45/100], Loss: 62.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [46/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [47/100], Loss: 12.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [48/100], Loss: 25.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [49/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [50/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [51/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [52/100], Loss: 62.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [53/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [54/100], Loss: 25.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [55/100], Loss: 25.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [56/100], Loss: 62.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [57/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [58/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [59/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [60/100], Loss: 25.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [61/100], Loss: 12.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [62/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [63/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [64/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [65/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [66/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [67/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [68/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [69/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [70/100], Loss: 75.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [71/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [72/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [73/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [74/100], Loss: 62.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [75/100], Loss: 62.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [76/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [77/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [78/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [79/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [80/100], Loss: 62.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [81/100], Loss: 75.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [82/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [83/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [84/100], Loss: 25.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [85/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [86/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [87/100], Loss: 62.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [88/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [89/100], Loss: 62.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [90/100], Loss: 75.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [91/100], Loss: 100.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [92/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [93/100], Loss: 62.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [94/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [95/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [96/100], Loss: 62.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [97/100], Loss: 37.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [98/100], Loss: 62.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [99/100], Loss: 50.0000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n",
            "Epoch [100/100], Loss: 12.5000, Validation Loss: 41.3408, Validation Accuracy: 0.5866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SUSF9OxyOQDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a-7fTSPmOaXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = combined_df[len(train_df):]\n",
        "\n",
        "X_test = X_test.select_dtypes(include=np.number)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test)\n",
        "    test_predictions = (test_outputs > 0.5).int().flatten().tolist()\n",
        "\n"
      ],
      "metadata": {
        "id": "S2jwQnkCJdNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(num_epochs)\n",
        "\n",
        "plt.plot(epochs, losses)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "_rAsjpAqPVQx",
        "outputId": "ac2a9619-d7f0-4aa2-811b-0f68c9526fa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corret = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i,data in enumerate(X):\n",
        "    # Convert data to a PyTorch tensor\n",
        "    data_tensor = torch.tensor(data, dtype=torch.float32)\n",
        "    y_val = model.forward(data_tensor)\n",
        "\n",
        "    # The print statement was incorrectly indented. Corrected indentation below:\n",
        "    print(f'{i + 1}.) {str(y_val)} \\t {data} \\t {y_val.argmax().item() == y[i]}')\n",
        "\n",
        "    if y_val.argmax().item() == y[i] :\n",
        "      corret += 1\n",
        "\n",
        "print(f'we goat {corret} correct out of ',len(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4FrtEPKPd3X",
        "outputId": "ad309e04-528a-4a27-cbd5-b0b246a19a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.) tensor([0.]) \t [ 0.82737724 -0.56573646  0.43279337 -0.47367361 -0.50244517] \t True\n",
            "2.) tensor([0.]) \t [-1.56610693  0.66386103  0.43279337 -0.47367361  0.78684529] \t False\n",
            "3.) tensor([0.]) \t [ 0.82737724 -0.25833709 -0.4745452  -0.47367361 -0.48885426] \t False\n",
            "4.) tensor([0.]) \t [-1.56610693  0.4333115   0.43279337 -0.47367361  0.42073024] \t False\n",
            "5.) tensor([0.]) \t [ 0.82737724  0.4333115  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "6.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.47811643] \t True\n",
            "7.) tensor([0.]) \t [-1.56610693  1.89345853 -0.4745452  -0.47367361  0.39581356] \t True\n",
            "8.) tensor([0.]) \t [ 0.82737724 -2.10273333  2.24747049  0.76762988 -0.22408312] \t True\n",
            "9.) tensor([0.]) \t [ 0.82737724 -0.18148724 -0.4745452   2.00893337 -0.42425614] \t False\n",
            "10.) tensor([0.]) \t [-0.36936484 -1.18053521  0.43279337 -0.47367361 -0.0429555 ] \t False\n",
            "11.) tensor([0.]) \t [ 0.82737724 -1.94903364  0.43279337  0.76762988 -0.31217238] \t False\n",
            "12.) tensor([0.]) \t [-1.56610693  2.2008579  -0.4745452  -0.47367361 -0.11384571] \t False\n",
            "13.) tensor([0.]) \t [ 0.82737724 -0.71943615 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "14.) tensor([0.]) \t [ 0.82737724  0.74071088  0.43279337  5.73284383 -0.01870931] \t True\n",
            "15.) tensor([0.]) \t [ 0.82737724 -1.18053521 -0.4745452  -0.47367361 -0.49027979] \t True\n",
            "16.) tensor([0.]) \t [-0.36936484  1.97030837 -0.4745452  -0.47367361 -0.32626666] \t False\n",
            "17.) tensor([0.]) \t [ 0.82737724 -2.10273333  3.15480905  0.76762988 -0.06199889] \t True\n",
            "18.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452  -0.47367361 -0.38667072] \t False\n",
            "19.) tensor([0.]) \t [ 0.82737724  0.12591213  0.43279337 -0.47367361 -0.28599728] \t True\n",
            "20.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50294854] \t False\n",
            "21.) tensor([0.]) \t [-0.36936484  0.4333115  -0.4745452  -0.47367361 -0.12491979] \t True\n",
            "22.) tensor([0.]) \t [-0.36936484  0.35646166 -0.4745452  -0.47367361 -0.38667072] \t False\n",
            "23.) tensor([0.]) \t [ 0.82737724 -1.10368536 -0.4745452  -0.47367361 -0.48675622] \t False\n",
            "24.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361  0.06635974] \t False\n",
            "25.) tensor([0.]) \t [ 0.82737724 -1.64163427  2.24747049  0.76762988 -0.22408312] \t True\n",
            "26.) tensor([0.]) \t [ 0.82737724  0.66386103  0.43279337  5.73284383 -0.01644416] \t False\n",
            "27.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50294854] \t True\n",
            "28.) tensor([0.]) \t [-1.56610693 -0.79628599  2.24747049  2.00893337  4.64700108] \t True\n",
            "29.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48977643] \t False\n",
            "30.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "31.) tensor([0.]) \t [-1.56610693  0.81756072 -0.4745452  -0.47367361 -0.09027202] \t True\n",
            "32.) tensor([0.]) \t [-1.56610693 -0.1046374   0.43279337 -0.47367361  2.30172882] \t False\n",
            "33.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t False\n",
            "34.) tensor([0.]) \t [-0.36936484  2.81565665 -0.4745452  -0.47367361 -0.43700744] \t True\n",
            "35.) tensor([0.]) \t [-1.56610693 -0.1046374   0.43279337 -0.47367361  1.0060617 ] \t True\n",
            "36.) tensor([0.]) \t [-1.56610693  0.97126041  0.43279337 -0.47367361  0.39858208] \t True\n",
            "37.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50286397] \t False\n",
            "38.) tensor([0.]) \t [ 0.82737724 -0.6425863  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "39.) tensor([0.]) \t [ 0.82737724 -0.87313583  1.34013193 -0.47367361 -0.28599728] \t True\n",
            "40.) tensor([0.]) \t [ 0.82737724 -1.18053521  0.43279337 -0.47367361 -0.42207354] \t False\n",
            "41.) tensor([0.]) \t [ 0.82737724  0.81756072  0.43279337 -0.47367361 -0.45764549] \t True\n",
            "42.) tensor([0.]) \t [-0.36936484 -0.18148724  0.43279337 -0.47367361 -0.22559322] \t True\n",
            "43.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "44.) tensor([0.]) \t [-0.36936484 -2.02588348  0.43279337  2.00893337  0.18876253] \t False\n",
            "45.) tensor([0.]) \t [ 0.82737724 -0.79628599 -0.4745452  -0.47367361 -0.48977643] \t False\n",
            "46.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "47.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337 -0.47367361 -0.336334  ] \t True\n",
            "48.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t False\n",
            "49.) tensor([0.]) \t [ 0.82737724 -0.1046374   1.34013193 -0.47367361 -0.21191774] \t True\n",
            "50.) tensor([0.]) \t [ 0.82737724 -0.87313583  0.43279337 -0.47367361 -0.29002422] \t True\n",
            "51.) tensor([0.]) \t [ 0.82737724 -1.71848411  3.15480905  0.76762988  0.15067374] \t True\n",
            "52.) tensor([0.]) \t [ 0.82737724 -0.6425863  -0.4745452  -0.47367361 -0.49137109] \t True\n",
            "53.) tensor([0.]) \t [-1.56610693  1.50920931  0.43279337 -0.47367361  0.89649679] \t False\n",
            "54.) tensor([0.]) \t [-0.36936484 -0.02778756  0.43279337 -0.47367361 -0.12491979] \t False\n",
            "55.) tensor([0.]) \t [-1.56610693  2.7388068  -0.4745452   0.76762988  0.59951015] \t True\n",
            "56.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361  0.06635974] \t False\n",
            "57.) tensor([0.]) \t [-0.36936484 -0.6425863  -0.4745452  -0.47367361 -0.43700744] \t False\n",
            "58.) tensor([0.]) \t [ 0.82737724 -0.06621248 -0.4745452  -0.47367361 -0.50286397] \t True\n",
            "59.) tensor([0.]) \t [-0.36936484 -1.8721838   0.43279337  2.00893337 -0.08968408] \t False\n",
            "60.) tensor([0.]) \t [ 0.82737724 -1.41108474  4.06214761  2.00893337  0.29589518] \t True\n",
            "61.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.50286397] \t True\n",
            "62.) tensor([0.]) \t [-1.56610693  0.66386103 -0.4745452  -0.47367361  0.96235332] \t False\n",
            "63.) tensor([0.]) \t [-1.56610693  1.20180994  0.43279337 -0.47367361  1.03232136] \t True\n",
            "64.) tensor([0.]) \t [ 0.82737724 -1.94903364  2.24747049  2.00893337 -0.08666388] \t True\n",
            "65.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361 -0.09027202] \t True\n",
            "66.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337  0.76762988 -0.34145224] \t False\n",
            "67.) tensor([0.]) \t [-0.36936484 -0.02778756 -0.4745452  -0.47367361 -0.43700744] \t False\n",
            "68.) tensor([0.]) \t [ 0.82737724 -0.79628599 -0.4745452  -0.47367361 -0.48415684] \t True\n",
            "69.) tensor([0.]) \t [ 0.82737724 -0.94998568  3.15480905  2.00893337 -0.48885426] \t False\n",
            "70.) tensor([0.]) \t [ 0.82737724 -0.25833709  1.34013193 -0.47367361 -0.47400493] \t True\n",
            "71.) tensor([0.]) \t [-0.36936484  0.20276197 -0.4745452  -0.47367361 -0.43700744] \t True\n",
            "72.) tensor([0.]) \t [ 0.82737724 -1.02683552  4.06214761  2.00893337  0.29589518] \t True\n",
            "73.) tensor([0.]) \t [-0.36936484 -0.6425863  -0.4745452  -0.47367361  0.83147785] \t True\n",
            "74.) tensor([0.]) \t [ 0.82737724 -0.25833709  0.43279337 -0.47367361 -0.35739086] \t True\n",
            "75.) tensor([0.]) \t [ 0.82737724  0.20276197 -0.4745452  -0.47367361  0.48910361] \t False\n",
            "76.) tensor([0.]) \t [ 0.82737724 -0.33518693 -0.4745452  -0.47367361 -0.4943913 ] \t True\n",
            "77.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "78.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "79.) tensor([0.]) \t [-0.36936484 -2.19264764 -0.4745452   2.00893337 -0.06451573] \t False\n",
            "80.) tensor([0.]) \t [ 0.82737724  0.04906229 -0.4745452  -0.47367361 -0.39724143] \t False\n",
            "81.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.46720947] \t True\n",
            "82.) tensor([0.]) \t [ 0.82737724 -0.02778756 -0.4745452  -0.47367361 -0.45714213] \t False\n",
            "83.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49162278] \t False\n",
            "84.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361  0.29992211] \t True\n",
            "85.) tensor([0.]) \t [-0.36936484 -0.94998568 -0.4745452  -0.47367361 -0.43700744] \t False\n",
            "86.) tensor([0.]) \t [ 0.82737724  0.27961182  2.24747049 -0.47367361 -0.32928686] \t False\n",
            "87.) tensor([0.]) \t [ 0.82737724 -1.02683552  0.43279337  3.25023685  0.04370822] \t True\n",
            "88.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "89.) tensor([0.]) \t [-1.56610693 -0.48888662  2.24747049  2.00893337  4.64700108] \t False\n",
            "90.) tensor([0.]) \t [ 0.82737724 -0.41203677 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "91.) tensor([0.]) \t [ 0.82737724 -0.02778756 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "92.) tensor([0.]) \t [ 0.82737724 -0.71943615 -0.4745452  -0.47367361 -0.49027979] \t True\n",
            "93.) tensor([0.]) \t [-1.56610693  1.27865978  0.43279337 -0.47367361  0.58331784] \t True\n",
            "94.) tensor([0.]) \t [ 0.82737724 -0.25833709  0.43279337  2.00893337 -0.23415046] \t True\n",
            "95.) tensor([0.]) \t [ 0.82737724  2.27770774 -0.4745452  -0.47367361 -0.50244517] \t True\n",
            "96.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "97.) tensor([0.]) \t [-1.56610693  3.19990586 -0.4745452  -0.47367361  0.04932982] \t True\n",
            "98.) tensor([0.]) \t [-1.56610693 -0.48888662 -0.4745452   0.76762988  0.6272779 ] \t False\n",
            "99.) tensor([0.]) \t [-0.36936484  0.35646166 -0.4745452   0.76762988 -0.18532385] \t False\n",
            "100.) tensor([0.]) \t [-0.36936484  0.35646166  0.43279337 -0.47367361 -0.12491979] \t True\n",
            "101.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "102.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "103.) tensor([0.]) \t [-1.56610693 -0.6425863  -0.4745452   0.76762988  0.90773798] \t True\n",
            "104.) tensor([0.]) \t [ 0.82737724  0.27961182 -0.4745452  -0.47367361 -0.47417204] \t True\n",
            "105.) tensor([0.]) \t [ 0.82737724  0.58701119  1.34013193 -0.47367361 -0.48885426] \t True\n",
            "106.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "107.) tensor([0.]) \t [ 0.82737724 -0.6425863  -0.4745452  -0.47367361 -0.4943913 ] \t False\n",
            "108.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49187446] \t False\n",
            "109.) tensor([0.]) \t [ 0.82737724  0.66386103 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "110.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337 -0.47367361 -0.16216896] \t False\n",
            "111.) tensor([0.]) \t [-1.56610693  1.35550962 -0.4745452  -0.47367361  0.39858208] \t True\n",
            "112.) tensor([0.]) \t [ 0.82737724 -1.14211029  0.43279337 -0.47367361 -0.35739086] \t True\n",
            "113.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "114.) tensor([0.]) \t [ 0.82737724 -0.71943615  0.43279337 -0.47367361 -0.45059835] \t True\n",
            "115.) tensor([0.]) \t [ 0.82737724 -0.94998568 -0.4745452  -0.47367361 -0.35730831] \t True\n",
            "116.) tensor([0.]) \t [ 0.82737724 -0.6425863  -0.4745452  -0.47367361 -0.48885426] \t True\n",
            "117.) tensor([0.]) \t [ 0.82737724  3.16148094 -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "118.) tensor([0.]) \t [-0.36936484 -0.02778756  0.43279337 -0.47367361 -0.22559322] \t True\n",
            "119.) tensor([0.]) \t [-1.56610693 -0.41203677 -0.4745452   0.76762988  4.33533223] \t True\n",
            "120.) tensor([0.]) \t [ 0.82737724 -2.10273333  3.15480905  2.00893337 -0.01870931] \t True\n",
            "121.) tensor([0.]) \t [-0.36936484 -0.6425863   1.34013193 -0.47367361  0.83147785] \t True\n",
            "122.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "123.) tensor([0.]) \t [-0.36936484  0.24118689  0.43279337 -0.47367361 -0.0429555 ] \t True\n",
            "124.) tensor([0.]) \t [-0.36936484  0.24118689 -0.4745452  -0.47367361 -0.38667072] \t False\n",
            "125.) tensor([0.]) \t [-1.56610693  1.89345853 -0.4745452   0.76762988  0.90773798] \t True\n",
            "126.) tensor([0.]) \t [ 0.82737724 -1.33423489  0.43279337 -0.47367361 -0.42207354] \t False\n",
            "127.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "128.) tensor([0.]) \t [ 0.82737724 -0.41203677 -0.4745452  -0.47367361 -0.50462576] \t False\n",
            "129.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337  0.76762988 -0.19824428] \t False\n",
            "130.) tensor([0.]) \t [ 0.82737724  1.20180994 -0.4745452  -0.47367361 -0.50798221] \t True\n",
            "131.) tensor([0.]) \t [ 0.82737724  0.27961182 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "132.) tensor([0.]) \t [ 0.82737724 -0.71943615 -0.4745452  -0.47367361 -0.50647211] \t True\n",
            "133.) tensor([0.]) \t [ 0.82737724  1.35550962  0.43279337 -0.47367361 -0.35646869] \t True\n",
            "134.) tensor([0.]) \t [-0.36936484 -0.02778756  0.43279337 -0.47367361 -0.12491979] \t False\n",
            "135.) tensor([0.]) \t [-0.36936484 -0.33518693 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "136.) tensor([0.]) \t [-0.36936484 -0.48888662 -0.4745452  -0.47367361 -0.34547918] \t True\n",
            "137.) tensor([0.]) \t [-1.56610693 -0.79628599 -0.4745452   2.00893337 -0.11921563] \t False\n",
            "138.) tensor([0.]) \t [-1.56610693  0.58701119  0.43279337 -0.47367361  0.42073024] \t True\n",
            "139.) tensor([0.]) \t [ 0.82737724 -1.02683552 -0.4745452  -0.47367361 -0.46284628] \t True\n",
            "140.) tensor([0.]) \t [-1.56610693 -0.41203677 -0.4745452  -0.47367361  0.94624557] \t True\n",
            "141.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452   2.00893337 -0.34145224] \t True\n",
            "142.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.49237783] \t False\n",
            "143.) tensor([0.]) \t [ 0.82737724 -0.41203677  0.43279337 -0.47367361 -0.32928686] \t False\n",
            "144.) tensor([0.]) \t [ 0.82737724 -0.79628599 -0.4745452  -0.47367361 -0.51251252] \t True\n",
            "145.) tensor([0.]) \t [-0.36936484 -0.87313583 -0.4745452  -0.47367361 -0.41687275] \t True\n",
            "146.) tensor([0.]) \t [-0.36936484 -0.79628599  0.43279337  0.76762988  0.0915281 ] \t True\n",
            "147.) tensor([0.]) \t [ 0.82737724 -0.18148724 -0.4745452  -0.47367361 -0.49145566] \t False\n",
            "148.) tensor([0.]) \t [ 0.82737724 -1.56478442  1.34013193  2.00893337  0.04370822] \t True\n",
            "149.) tensor([0.]) \t [-0.36936484  0.54858627 -0.4745452   2.00893337 -0.12491979] \t True\n",
            "150.) tensor([0.]) \t [-0.36936484  0.97126041 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "151.) tensor([0.]) \t [-0.36936484  1.662909   -0.4745452  -0.47367361 -0.3962347 ] \t True\n",
            "152.) tensor([0.]) \t [-1.56610693 -0.56573646  0.43279337 -0.47367361  0.69254851] \t False\n",
            "153.) tensor([0.]) \t [ 0.82737724  2.00873329 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "154.) tensor([0.]) \t [ 0.82737724  0.85598564 -0.4745452   2.00893337 -0.35646869] \t True\n",
            "155.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50118675] \t True\n",
            "156.) tensor([0.]) \t [-1.56610693  1.662909   -0.4745452   0.76762988  0.58742934] \t True\n",
            "157.) tensor([0.]) \t [ 0.82737724 -1.02683552 -0.4745452  -0.47367361 -0.49271408] \t False\n",
            "158.) tensor([0.]) \t [ 0.82737724  0.04906229 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "159.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.47400493] \t True\n",
            "160.) tensor([0.]) \t [ 0.82737724 -0.1046374   6.7841633   2.00893337  0.75194584] \t True\n",
            "161.) tensor([0.]) \t [ 0.82737724  1.12496009 -0.4745452   0.76762988 -0.32425319] \t True\n",
            "162.) tensor([0.]) \t [-0.36936484  0.81756072 -0.4745452  -0.47367361 -0.33130033] \t False\n",
            "163.) tensor([0.]) \t [ 0.82737724 -0.25833709 -0.4745452  -0.47367361 -0.49187446] \t True\n",
            "164.) tensor([0.]) \t [ 0.82737724 -0.94998568 -0.4745452  -0.47367361 -0.47400493] \t True\n",
            "165.) tensor([0.]) \t [ 0.82737724 -2.17958317  3.15480905  0.76762988  0.15067374] \t True\n",
            "166.) tensor([0.]) \t [ 0.82737724 -1.56478442 -0.4745452   2.00893337 -0.2351572 ] \t False\n",
            "167.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452   0.76762988  0.45898614] \t False\n",
            "168.) tensor([0.]) \t [ 0.82737724  1.20180994  0.43279337  4.49154034 -0.08666388] \t True\n",
            "169.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361 -0.12642989] \t True\n",
            "170.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361  0.48910361] \t True\n",
            "171.) tensor([0.]) \t [-1.56610693  2.43140743 -0.4745452  -0.47367361  0.02609037] \t True\n",
            "172.) tensor([0.]) \t [ 0.82737724 -1.94903364  3.15480905  0.76762988 -0.06199889] \t True\n",
            "173.) tensor([0.]) \t [ 0.82737724 -2.17958317  0.43279337  0.76762988 -0.42425614] \t False\n",
            "174.) tensor([0.]) \t [ 0.82737724 -0.6425863  -0.4745452  -0.47367361 -0.48885426] \t True\n",
            "175.) tensor([0.]) \t [-1.56610693  2.04715821 -0.4745452  -0.47367361 -0.03037132] \t True\n",
            "176.) tensor([0.]) \t [ 0.82737724 -0.87313583  0.43279337  0.76762988 -0.49027979] \t True\n",
            "177.) tensor([0.]) \t [ 0.82737724 -0.1046374   2.24747049  0.76762988 -0.13565762] \t True\n",
            "178.) tensor([0.]) \t [-1.56610693  1.58605915 -0.4745452  -0.47367361 -0.07030445] \t True\n",
            "179.) tensor([0.]) \t [-0.36936484  0.04906229 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "180.) tensor([0.]) \t [ 0.82737724  0.51016135 -0.4745452  -0.47367361 -0.64842165] \t True\n",
            "181.) tensor([0.]) \t [ 0.82737724 -0.1046374   6.7841633   2.00893337  0.75194584] \t True\n",
            "182.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452  -0.47367361 -0.34539461] \t True\n",
            "183.) tensor([0.]) \t [ 0.82737724 -1.56478442  3.15480905  2.00893337 -0.01644416] \t True\n",
            "184.) tensor([0.]) \t [-0.36936484 -2.17958317  1.34013193  0.76762988  0.13683115] \t False\n",
            "185.) tensor([0.]) \t [ 0.82737724 -1.94903364 -0.4745452   2.00893337 -0.20495517] \t False\n",
            "186.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361  0.35831271] \t True\n",
            "187.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337 -0.47367361 -0.336334  ] \t False\n",
            "188.) tensor([0.]) \t [-1.56610693  1.20180994 -0.4745452  -0.47367361 -0.11384571] \t False\n",
            "189.) tensor([0.]) \t [ 0.82737724  0.81756072  0.43279337  0.76762988 -0.336334  ] \t True\n",
            "190.) tensor([0.]) \t [ 0.82737724  0.51016135 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "191.) tensor([0.]) \t [-0.36936484  0.20276197 -0.4745452  -0.47367361 -0.38667072] \t False\n",
            "192.) tensor([0.]) \t [-0.36936484 -0.79628599 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "193.) tensor([0.]) \t [ 0.82737724 -0.79628599  0.43279337 -0.47367361 -0.49027979] \t False\n",
            "194.) tensor([0.]) \t [-0.36936484 -2.02588348  0.43279337  0.76762988 -0.12491979] \t False\n",
            "195.) tensor([0.]) \t [-1.56610693  1.12496009 -0.4745452  -0.47367361 -0.09027202] \t False\n",
            "196.) tensor([0.]) \t [-1.56610693  2.2008579  -0.4745452  -0.47367361  2.30172882] \t False\n",
            "197.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "198.) tensor([0.]) \t [ 0.82737724  0.97126041 -0.4745452   0.76762988 -0.47920572] \t True\n",
            "199.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t False\n",
            "200.) tensor([0.]) \t [-0.36936484 -0.41203677 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "201.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.45714213] \t True\n",
            "202.) tensor([0.]) \t [ 0.82737724 -0.1046374   6.7841633   2.00893337  0.75194584] \t True\n",
            "203.) tensor([0.]) \t [ 0.82737724  0.35646166 -0.4745452  -0.47367361 -0.51763075] \t True\n",
            "204.) tensor([0.]) \t [ 0.82737724  1.24023486 -0.4745452  -0.47367361 -0.50294854] \t True\n",
            "205.) tensor([0.]) \t [ 0.82737724 -0.87313583 -0.4745452  -0.47367361 -0.48633742] \t False\n",
            "206.) tensor([0.]) \t [ 0.82737724 -2.10273333 -0.4745452   0.76762988 -0.43776249] \t True\n",
            "207.) tensor([0.]) \t [ 0.82737724  0.20276197  0.43279337 -0.47367361 -0.32928686] \t True\n",
            "208.) tensor([0.]) \t [ 0.82737724 -0.25833709 -0.4745452  -0.47367361 -0.27014122] \t False\n",
            "209.) tensor([0.]) \t [ 0.82737724 -1.02683552 -0.4745452  -0.47367361 -0.49237783] \t False\n",
            "210.) tensor([0.]) \t [-1.56610693  0.81756072 -0.4745452  -0.47367361 -0.02424635] \t False\n",
            "211.) tensor([0.]) \t [ 0.82737724 -0.41203677 -0.4745452  -0.47367361 -0.50647211] \t True\n",
            "212.) tensor([0.]) \t [-0.36936484  0.4333115  -0.4745452  -0.47367361 -0.22559322] \t False\n",
            "213.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.50244517] \t True\n",
            "214.) tensor([0.]) \t [-0.36936484  0.04906229 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "215.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337 -0.47367361 -0.49237783] \t True\n",
            "216.) tensor([0.]) \t [-1.56610693  0.12591213  0.43279337 -0.47367361  1.63233504] \t False\n",
            "217.) tensor([0.]) \t [ 0.82737724 -0.18148724 -0.4745452  -0.47367361 -0.48885426] \t False\n",
            "218.) tensor([0.]) \t [-0.36936484  0.97126041  0.43279337 -0.47367361 -0.1047851 ] \t True\n",
            "219.) tensor([0.]) \t [-1.56610693  0.20276197 -0.4745452  -0.47367361  0.88768786] \t False\n",
            "220.) tensor([0.]) \t [-0.36936484  0.04906229 -0.4745452  -0.47367361 -0.43700744] \t True\n",
            "221.) tensor([0.]) \t [ 0.82737724 -1.02683552 -0.4745452  -0.47367361 -0.48633742] \t False\n",
            "222.) tensor([0.]) \t [-0.36936484 -0.18148724 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "223.) tensor([0.]) \t [ 0.82737724  1.662909   -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "224.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "225.) tensor([0.]) \t [-1.56610693  0.66386103  0.43279337 -0.47367361  1.16370019] \t False\n",
            "226.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.46016233] \t True\n",
            "227.) tensor([0.]) \t [-0.36936484 -0.79628599 -0.4745452  -0.47367361 -0.43700744] \t False\n",
            "228.) tensor([0.]) \t [ 0.82737724 -0.68101123 -0.4745452  -0.47367361 -0.50244517] \t True\n",
            "229.) tensor([0.]) \t [-0.36936484 -0.87313583 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "230.) tensor([0.]) \t [ 0.82737724 -0.1046374   2.24747049  0.76762988 -0.13565762] \t True\n",
            "231.) tensor([0.]) \t [-1.56610693  0.4333115   0.43279337 -0.47367361  1.03232136] \t False\n",
            "232.) tensor([0.]) \t [ 0.82737724 -0.02778756 -0.4745452  -0.47367361 -0.49187446] \t True\n",
            "233.) tensor([0.]) \t [-0.36936484  2.27770774 -0.4745452  -0.47367361 -0.37660338] \t True\n",
            "234.) tensor([0.]) \t [ 0.82737724 -1.8721838   3.15480905  2.00893337 -0.01644416] \t False\n",
            "235.) tensor([0.]) \t [-0.36936484 -0.41203677 -0.4745452  -0.47367361 -0.43700744] \t True\n",
            "236.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49640477] \t True\n",
            "237.) tensor([0.]) \t [-0.36936484  1.12496009  0.43279337 -0.47367361 -0.12491979] \t True\n",
            "238.) tensor([0.]) \t [-0.36936484 -1.64163427 -0.4745452   2.00893337 -0.11988611] \t False\n",
            "239.) tensor([0.]) \t [-0.36936484 -0.79628599 -0.4745452  -0.47367361 -0.43700744] \t True\n",
            "240.) tensor([0.]) \t [-0.36936484  0.27961182 -0.4745452  -0.47367361 -0.40126837] \t True\n",
            "241.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337 -0.47367361 -0.35739086] \t True\n",
            "242.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337 -0.47367361 -0.336334  ] \t False\n",
            "243.) tensor([0.]) \t [-0.36936484 -0.02778756 -0.4745452  -0.47367361 -0.43700744] \t True\n",
            "244.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.50496201] \t True\n",
            "245.) tensor([0.]) \t [ 0.82737724  0.04906229 -0.4745452  -0.47367361 -0.50294854] \t True\n",
            "246.) tensor([0.]) \t [-1.56610693  1.12496009  1.34013193 -0.47367361  1.16370019] \t True\n",
            "247.) tensor([0.]) \t [ 0.82737724 -0.33518693 -0.4745452  -0.47367361 -0.49187446] \t True\n",
            "248.) tensor([0.]) \t [-0.36936484 -0.41203677 -0.4745452   2.00893337 -0.35646869] \t False\n",
            "249.) tensor([0.]) \t [-1.56610693  0.58701119  0.43279337  0.76762988  0.40974072] \t False\n",
            "250.) tensor([0.]) \t [-0.36936484  1.89345853  0.43279337 -0.47367361 -0.12491979] \t True\n",
            "251.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50244517] \t True\n",
            "252.) tensor([0.]) \t [ 0.82737724 -0.02778756  0.43279337  0.76762988 -0.43776249] \t True\n",
            "253.) tensor([0.]) \t [-1.56610693  2.50825727 -0.4745452  -0.47367361 -0.11384571] \t True\n",
            "254.) tensor([0.]) \t [ 0.82737724  0.04906229  0.43279337 -0.47367361 -0.32425319] \t True\n",
            "255.) tensor([0.]) \t [ 0.82737724  0.89441056 -0.4745452   2.00893337 -0.24144929] \t True\n",
            "256.) tensor([0.]) \t [ 0.82737724 -0.02778756 -0.4745452   2.00893337 -0.34145224] \t False\n",
            "257.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361  0.94624557] \t False\n",
            "258.) tensor([0.]) \t [-1.56610693  0.04906229 -0.4745452  -0.47367361  1.09322879] \t False\n",
            "259.) tensor([0.]) \t [-1.56610693  0.4333115  -0.4745452  -0.47367361  9.66716653] \t False\n",
            "260.) tensor([0.]) \t [-0.36936484  1.58605915 -0.4745452   0.76762988 -0.12491979] \t False\n",
            "261.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "262.) tensor([0.]) \t [ 0.82737724 -2.02588348  3.15480905  2.00893337 -0.01644416] \t False\n",
            "263.) tensor([0.]) \t [-1.56610693  1.73975884  0.43279337  0.76762988  0.95530618] \t True\n",
            "264.) tensor([0.]) \t [-1.56610693  0.81756072 -0.4745452  -0.47367361 -0.64842165] \t True\n",
            "265.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "266.) tensor([0.]) \t [-0.36936484  0.51016135 -0.4745452  -0.47367361 -0.43700744] \t True\n",
            "267.) tensor([0.]) \t [ 0.82737724 -1.02683552  3.15480905  0.76762988  0.15067374] \t True\n",
            "268.) tensor([0.]) \t [ 0.82737724 -0.33518693  0.43279337 -0.47367361 -0.49187446] \t False\n",
            "269.) tensor([0.]) \t [-1.56610693  2.2008579  -0.4745452   0.76762988  2.44149778] \t False\n",
            "270.) tensor([0.]) \t [-1.56610693  0.4333115  -0.4745452  -0.47367361  2.08251241] \t False\n",
            "271.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361 -0.02424635] \t True\n",
            "272.) tensor([0.]) \t [ 0.82737724 -0.33518693 -0.4745452  -0.47367361 -0.64842165] \t False\n",
            "273.) tensor([0.]) \t [-0.36936484  0.89441056 -0.4745452   0.76762988 -0.25579525] \t False\n",
            "274.) tensor([0.]) \t [-1.56610693  0.58701119 -0.4745452   0.76762988 -0.05042144] \t True\n",
            "275.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t False\n",
            "276.) tensor([0.]) \t [-1.56610693  2.58510712  0.43279337 -0.47367361  0.92124433] \t False\n",
            "277.) tensor([0.]) \t [ 0.82737724  1.20180994 -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "278.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452  -0.47367361 -0.64842165] \t True\n",
            "279.) tensor([0.]) \t [ 0.82737724 -1.71848411  3.15480905  0.76762988 -0.06199889] \t True\n",
            "280.) tensor([0.]) \t [ 0.82737724  0.4333115   0.43279337  0.76762988 -0.24069424] \t False\n",
            "281.) tensor([0.]) \t [ 0.82737724  2.7388068  -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "282.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49027979] \t True\n",
            "283.) tensor([0.]) \t [ 0.82737724 -1.02683552 -0.4745452  -0.47367361 -0.45714213] \t True\n",
            "284.) tensor([0.]) \t [ 0.82737724 -0.79628599 -0.4745452  -0.47367361 -0.48633742] \t False\n",
            "285.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361 -0.12491979] \t True\n",
            "286.) tensor([0.]) \t [ 0.82737724  0.27961182 -0.4745452  -0.47367361 -0.47400493] \t True\n",
            "287.) tensor([0.]) \t [ 0.82737724  0.04906229 -0.4745452  -0.47367361 -0.45714213] \t False\n",
            "288.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "289.) tensor([0.]) \t [-0.36936484  0.97126041 -0.4745452  -0.47367361 -0.38667072] \t False\n",
            "290.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.49237783] \t False\n",
            "291.) tensor([0.]) \t [-1.56610693 -0.25833709 -0.4745452  -0.47367361  0.93919843] \t False\n",
            "292.) tensor([0.]) \t [-1.56610693 -0.79628599  0.43279337 -0.47367361  1.18542955] \t False\n",
            "293.) tensor([0.]) \t [-0.36936484  0.51016135 -0.4745452  -0.47367361 -0.38918756] \t True\n",
            "294.) tensor([0.]) \t [ 0.82737724 -0.41203677 -0.4745452  -0.47367361 -0.47022967] \t True\n",
            "295.) tensor([0.]) \t [ 0.82737724 -0.41203677 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "296.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361 -0.09027202] \t True\n",
            "297.) tensor([0.]) \t [ 0.82737724 -0.4504617  -0.4745452  -0.47367361 -0.50286397] \t True\n",
            "298.) tensor([0.]) \t [-1.56610693 -2.10273333  0.43279337  2.00893337  2.40299019] \t True\n",
            "299.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361 -0.03431369] \t False\n",
            "300.) tensor([0.]) \t [-1.56610693  1.58605915 -0.4745452   0.76762988  4.33533223] \t False\n",
            "301.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t False\n",
            "302.) tensor([0.]) \t [ 0.82737724 -0.1046374   1.34013193 -0.47367361 -0.18029018] \t False\n",
            "303.) tensor([0.]) \t [ 0.82737724 -0.79628599 -0.4745452  -0.47367361 -0.64842165] \t True\n",
            "304.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452  -0.47367361 -0.39975827] \t False\n",
            "305.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "306.) tensor([0.]) \t [-1.56610693 -2.18573116  0.43279337  2.00893337  2.40299019] \t False\n",
            "307.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361  1.58417891] \t False\n",
            "308.) tensor([0.]) \t [-1.56610693 -0.94998568  0.43279337 -0.47367361  1.54424578] \t False\n",
            "309.) tensor([0.]) \t [-0.36936484  0.04906229  0.43279337 -0.47367361 -0.16518916] \t True\n",
            "310.) tensor([0.]) \t [-1.56610693  0.04906229 -0.4745452  -0.47367361  0.49782998] \t False\n",
            "311.) tensor([0.]) \t [-1.56610693 -0.41203677 -0.4745452  -0.47367361  1.0259447 ] \t False\n",
            "312.) tensor([0.]) \t [-1.56610693 -0.87313583  1.34013193  2.00893337  4.6344169 ] \t False\n",
            "313.) tensor([0.]) \t [-0.36936484 -0.25833709  0.43279337  0.76762988 -0.12491979] \t True\n",
            "314.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "315.) tensor([0.]) \t [-0.36936484  1.04811025  0.43279337  0.76762988 -0.11988611] \t True\n",
            "316.) tensor([0.]) \t [ 0.82737724 -0.25833709 -0.4745452  -0.47367361 -0.49027979] \t False\n",
            "317.) tensor([0.]) \t [-0.36936484 -0.41203677  0.43279337 -0.47367361 -0.12491979] \t False\n",
            "318.) tensor([0.]) \t [-0.36936484  1.89345853 -0.4745452  -0.47367361 -0.36653603] \t True\n",
            "319.) tensor([0.]) \t [-1.56610693  0.12591213 -0.4745452   2.00893337  2.67111778] \t False\n",
            "320.) tensor([0.]) \t [-1.56610693  0.81756072  0.43279337  0.76762988  2.05969377] \t False\n",
            "321.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.50244517] \t True\n",
            "322.) tensor([0.]) \t [ 0.82737724 -0.18148724 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "323.) tensor([0.]) \t [-0.36936484  0.04906229 -0.4745452  -0.47367361 -0.39975827] \t False\n",
            "324.) tensor([0.]) \t [-0.36936484 -0.56573646  0.43279337  0.76762988 -0.06451573] \t False\n",
            "325.) tensor([0.]) \t [ 0.82737724 -0.1046374   6.7841633   2.00893337  0.75194584] \t True\n",
            "326.) tensor([0.]) \t [-1.56610693  0.51016135 -0.4745452  -0.47367361  2.08251241] \t False\n",
            "327.) tensor([0.]) \t [ 0.82737724  2.43140743 -0.4745452  -0.47367361 -0.52283154] \t True\n",
            "328.) tensor([0.]) \t [-0.36936484  0.51016135 -0.4745452  -0.47367361 -0.38667072] \t False\n",
            "329.) tensor([0.]) \t [ 0.82737724  0.12591213  0.43279337  0.76762988 -0.2351572 ] \t False\n",
            "330.) tensor([0.]) \t [-1.56610693 -1.02683552 -0.4745452   0.76762988  0.5189714 ] \t False\n",
            "331.) tensor([0.]) \t [ 0.82737724 -0.1046374   1.34013193 -0.47367361 -0.18029018] \t False\n",
            "332.) tensor([0.]) \t [-1.56610693  1.24023486 -0.4745452  -0.47367361 -0.07458307] \t True\n",
            "333.) tensor([0.]) \t [-1.56610693  0.66386103 -0.4745452   0.76762988  2.44149778] \t True\n",
            "334.) tensor([0.]) \t [ 0.82737724 -1.02683552  1.34013193 -0.47367361 -0.28599728] \t True\n",
            "335.) tensor([0.]) \t [-1.56610693 -0.1046374   0.43279337 -0.47367361  2.04257929] \t False\n",
            "336.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "337.) tensor([0.]) \t [-1.56610693 -0.02778756  0.43279337 -0.47367361  0.69254851] \t True\n",
            "338.) tensor([0.]) \t [-1.56610693  0.89441056 -0.4745452  -0.47367361  2.05969377] \t False\n",
            "339.) tensor([0.]) \t [ 0.82737724  1.20180994 -0.4745452  -0.47367361 -0.48633742] \t False\n",
            "340.) tensor([0.]) \t [-1.56610693  1.20180994 -0.4745452  -0.47367361  0.06635974] \t True\n",
            "341.) tensor([0.]) \t [-0.36936484 -2.10273333  0.43279337  0.76762988 -0.12491979] \t False\n",
            "342.) tensor([0.]) \t [-1.56610693 -0.41203677  2.24747049  2.00893337  4.64700108] \t False\n",
            "343.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "344.) tensor([0.]) \t [-0.36936484 -0.33518693 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "345.) tensor([0.]) \t [-0.36936484  0.51016135 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "346.) tensor([0.]) \t [-0.36936484 -0.41203677 -0.4745452  -0.47367361 -0.38667072] \t False\n",
            "347.) tensor([0.]) \t [-0.36936484  0.81756072 -0.4745452  -0.47367361 -0.38667072] \t False\n",
            "348.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337 -0.47367361 -0.32425319] \t False\n",
            "349.) tensor([0.]) \t [ 0.82737724 -2.02588348  0.43279337  0.76762988 -0.32828013] \t False\n",
            "350.) tensor([0.]) \t [ 0.82737724  0.97126041 -0.4745452  -0.47367361 -0.47400493] \t True\n",
            "351.) tensor([0.]) \t [ 0.82737724 -0.48888662 -0.4745452  -0.47367361 -0.46267916] \t True\n",
            "352.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361  0.0562924 ] \t True\n",
            "353.) tensor([0.]) \t [ 0.82737724 -1.10368536  0.43279337  0.76762988 -0.50286397] \t True\n",
            "354.) tensor([0.]) \t [ 0.82737724 -0.33518693  0.43279337 -0.47367361 -0.29002422] \t True\n",
            "355.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50294854] \t True\n",
            "356.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.45714213] \t True\n",
            "357.) tensor([0.]) \t [-1.56610693 -0.56573646 -0.4745452   0.76762988  0.45898614] \t False\n",
            "358.) tensor([0.]) \t [-0.36936484  0.66386103 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "359.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48977643] \t False\n",
            "360.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48977643] \t False\n",
            "361.) tensor([0.]) \t [ 0.82737724  0.81756072  0.43279337  4.49154034 -0.08666388] \t True\n",
            "362.) tensor([0.]) \t [-0.36936484 -0.02778756  0.43279337 -0.47367361 -0.09027202] \t True\n",
            "363.) tensor([0.]) \t [ 0.82737724  1.20180994 -0.4745452   0.76762988 -0.35739086] \t True\n",
            "364.) tensor([0.]) \t [ 0.82737724  0.4333115  -0.4745452  -0.47367361 -0.50647211] \t True\n",
            "365.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337 -0.47367361 -0.336334  ] \t True\n",
            "366.) tensor([0.]) \t [ 0.82737724  0.04906229 -0.4745452  -0.47367361 -0.50244517] \t True\n",
            "367.) tensor([0.]) \t [-1.56610693  2.35455759  0.43279337 -0.47367361  0.86671356] \t False\n",
            "368.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50286397] \t False\n",
            "369.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t False\n",
            "370.) tensor([0.]) \t [-1.56610693 -0.41203677 -0.4745452  -0.47367361  0.74691217] \t False\n",
            "371.) tensor([0.]) \t [-1.56610693 -0.33518693  0.43279337 -0.47367361  0.46787963] \t False\n",
            "372.) tensor([0.]) \t [ 0.82737724 -0.87313583  0.43279337 -0.47367361 -0.51763075] \t True\n",
            "373.) tensor([0.]) \t [ 0.82737724 -0.79628599 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "374.) tensor([0.]) \t [-1.56610693 -0.56573646 -0.4745452  -0.47367361  2.08251241] \t True\n",
            "375.) tensor([0.]) \t [ 0.82737724 -2.02588348  2.24747049  0.76762988 -0.22408312] \t True\n",
            "376.) tensor([0.]) \t [-1.56610693 -0.1046374   0.43279337 -0.47367361  1.0060617 ] \t False\n",
            "377.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.50244517] \t False\n",
            "378.) tensor([0.]) \t [-1.56610693 -0.18148724 -0.4745452   2.00893337  3.61006469] \t True\n",
            "379.) tensor([0.]) \t [ 0.82737724 -0.71943615 -0.4745452  -0.47367361 -0.56763122] \t True\n",
            "380.) tensor([0.]) \t [ 0.82737724 -0.79628599 -0.4745452  -0.47367361 -0.49187446] \t True\n",
            "381.) tensor([0.]) \t [-1.56610693  0.97126041 -0.4745452  -0.47367361  3.93272305] \t False\n",
            "382.) tensor([0.]) \t [ 0.82737724 -2.17958317 -0.4745452   2.00893337 -0.33146745] \t False\n",
            "383.) tensor([0.]) \t [ 0.82737724  0.20276197 -0.4745452  -0.47367361 -0.48885426] \t True\n",
            "384.) tensor([0.]) \t [-1.56610693  0.4333115   0.43279337 -0.47367361  0.39858208] \t False\n",
            "385.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "386.) tensor([0.]) \t [-0.36936484 -0.87313583 -0.4745452  -0.47367361  0.83147785] \t True\n",
            "387.) tensor([0.]) \t [ 0.82737724 -2.17958317  4.06214761  2.00893337  0.29589518] \t True\n",
            "388.) tensor([0.]) \t [-0.36936484  0.51016135 -0.4745452  -0.47367361 -0.38667072] \t False\n",
            "389.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49279663] \t True\n",
            "390.) tensor([0.]) \t [-0.36936484 -0.94998568 -0.4745452  -0.47367361 -0.40680541] \t False\n",
            "391.) tensor([0.]) \t [-1.56610693  0.51016135  0.43279337  2.00893337  1.76774081] \t False\n",
            "392.) tensor([0.]) \t [ 0.82737724 -0.6425863  -0.4745452  -0.47367361 -0.49145566] \t False\n",
            "393.) tensor([0.]) \t [ 0.82737724 -0.1046374   1.34013193 -0.47367361 -0.48885426] \t True\n",
            "394.) tensor([0.]) \t [-1.56610693 -0.48888662  0.43279337 -0.47367361  1.63233504] \t False\n",
            "395.) tensor([0.]) \t [ 0.82737724 -0.41203677 -0.4745452   2.00893337 -0.31217238] \t False\n",
            "396.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.49145566] \t True\n",
            "397.) tensor([0.]) \t [ 0.82737724  0.12591213 -0.4745452  -0.47367361 -0.49027979] \t True\n",
            "398.) tensor([0.]) \t [-0.36936484  1.27865978 -0.4745452  -0.47367361 -0.12491979] \t True\n",
            "399.) tensor([0.]) \t [-0.36936484 -0.48888662 -0.4745452  -0.47367361 -0.43700744] \t True\n",
            "400.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452  -0.47367361 -0.39371786] \t False\n",
            "401.) tensor([0.]) \t [ 0.82737724  0.74071088 -0.4745452  -0.47367361 -0.48885426] \t False\n",
            "402.) tensor([0.]) \t [ 0.82737724 -0.25833709 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "403.) tensor([0.]) \t [ 0.82737724 -0.6425863   0.43279337 -0.47367361 -0.45059835] \t True\n",
            "404.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337 -0.47367361 -0.32928686] \t True\n",
            "405.) tensor([0.]) \t [ 0.82737724 -0.71943615 -0.4745452  -0.47367361 -0.47400493] \t True\n",
            "406.) tensor([0.]) \t [-0.36936484  0.35646166  0.43279337 -0.47367361 -0.22559322] \t True\n",
            "407.) tensor([0.]) \t [ 0.82737724  1.662909   -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "408.) tensor([0.]) \t [-0.36936484 -2.02588348  0.43279337  0.76762988 -0.27089627] \t False\n",
            "409.) tensor([0.]) \t [ 0.82737724 -0.6425863  -0.4745452  -0.47367361 -0.49187446] \t True\n",
            "410.) tensor([0.]) \t [ 0.82737724 -0.1046374   2.24747049  0.76762988 -0.13565762] \t True\n",
            "411.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "412.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.51033193] \t True\n",
            "413.) tensor([0.]) \t [-1.56610693  0.27961182  0.43279337 -0.47367361  1.16370019] \t False\n",
            "414.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452  -0.47367361 -0.64842165] \t True\n",
            "415.) tensor([0.]) \t [ 0.82737724  1.12496009 -0.4745452  -0.47367361 -0.48885426] \t False\n",
            "416.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "417.) tensor([0.]) \t [-0.36936484  0.35646166  0.43279337  0.76762988  0.00595568] \t False\n",
            "418.) tensor([0.]) \t [-0.36936484 -0.87313583 -0.4745452   2.00893337 -0.38667072] \t False\n",
            "419.) tensor([0.]) \t [-0.36936484  0.04906229 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "420.) tensor([0.]) \t [ 0.82737724 -1.48793458 -0.4745452   2.00893337 -0.16216896] \t True\n",
            "421.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "422.) tensor([0.]) \t [ 0.82737724 -0.6425863  -0.4745452  -0.47367361 -0.49271408] \t True\n",
            "423.) tensor([0.]) \t [ 0.82737724 -0.02778756 -0.4745452  -0.47367361 -0.48986099] \t True\n",
            "424.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337  0.76762988 -0.35848216] \t True\n",
            "425.) tensor([0.]) \t [ 0.82737724 -0.87313583  0.43279337  0.76762988 -0.24144929] \t True\n",
            "426.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50244517] \t True\n",
            "427.) tensor([0.]) \t [-0.36936484 -0.1046374   0.43279337 -0.47367361 -0.12491979] \t False\n",
            "428.) tensor([0.]) \t [-0.36936484 -0.79628599 -0.4745452  -0.47367361 -0.12491979] \t False\n",
            "429.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "430.) tensor([0.]) \t [ 0.82737724  0.20276197 -0.4745452  -0.47367361 -0.48633742] \t False\n",
            "431.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361 -0.11384571] \t False\n",
            "432.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337 -0.47367361 -0.32425319] \t False\n",
            "433.) tensor([0.]) \t [-0.36936484  0.97126041  0.43279337 -0.47367361 -0.12491979] \t False\n",
            "434.) tensor([0.]) \t [ 0.82737724 -0.94998568 -0.4745452  -0.47367361 -0.50496201] \t True\n",
            "435.) tensor([0.]) \t [-1.56610693  1.58605915  0.43279337 -0.47367361  0.47710736] \t True\n",
            "436.) tensor([0.]) \t [-1.56610693 -1.18053521  0.43279337  2.00893337  1.76774081] \t False\n",
            "437.) tensor([0.]) \t [ 0.82737724 -0.6425863   1.34013193  2.00893337  0.04370822] \t True\n",
            "438.) tensor([0.]) \t [-0.36936484 -0.41203677  1.34013193  3.25023685 -0.27089627] \t False\n",
            "439.) tensor([0.]) \t [-1.56610693  2.66195696  0.43279337  4.49154034  4.64700108] \t True\n",
            "440.) tensor([0.]) \t [-0.36936484  0.12591213 -0.4745452  -0.47367361 -0.43700744] \t True\n",
            "441.) tensor([0.]) \t [-0.36936484  1.20180994  0.43279337  0.76762988 -0.11988611] \t False\n",
            "442.) tensor([0.]) \t [ 0.82737724 -0.71943615 -0.4745452  -0.47367361 -0.45714213] \t True\n",
            "443.) tensor([0.]) \t [ 0.82737724 -0.33518693  0.43279337 -0.47367361 -0.49187446] \t True\n",
            "444.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452  -0.47367361 -0.38667072] \t False\n",
            "445.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.485079  ] \t False\n",
            "446.) tensor([0.]) \t [-1.56610693 -1.94903364 -0.4745452   2.00893337  0.99976961] \t False\n",
            "447.) tensor([0.]) \t [-0.36936484 -1.25738505 -0.4745452   0.76762988 -0.25579525] \t False\n",
            "448.) tensor([0.]) \t [-1.56610693  0.35646166 -0.4745452  -0.47367361 -0.11384571] \t False\n",
            "449.) tensor([0.]) \t [ 0.82737724 -1.8721838   1.34013193  0.76762988 -0.26066181] \t False\n",
            "450.) tensor([0.]) \t [-1.56610693  1.73975884 -0.4745452  -0.47367361 -0.03431369] \t False\n",
            "451.) tensor([0.]) \t [-0.36936484  0.51016135  0.43279337  2.00893337 -0.08968408] \t True\n",
            "452.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337 -0.47367361 -0.24639839] \t True\n",
            "453.) tensor([0.]) \t [-1.56610693  0.04906229 -0.4745452  -0.47367361 -0.08968408] \t True\n",
            "454.) tensor([0.]) \t [-1.56610693  1.50920931  0.43279337 -0.47367361  1.14566354] \t False\n",
            "455.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "456.) tensor([0.]) \t [ 0.82737724 -0.02778756 -0.4745452  -0.47367361 -0.48944219] \t False\n",
            "457.) tensor([0.]) \t [-1.56610693  2.7388068  -0.4745452  -0.47367361 -0.11384571] \t True\n",
            "458.) tensor([0.]) \t [-1.56610693 -0.1046374   0.43279337 -0.47367361  0.39581356] \t False\n",
            "459.) tensor([0.]) \t [-0.36936484  1.58605915 -0.4745452  -0.47367361 -0.43700744] \t False\n",
            "460.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "461.) tensor([0.]) \t [-1.56610693  1.43235947 -0.4745452  -0.47367361 -0.11384571] \t False\n",
            "462.) tensor([0.]) \t [ 0.82737724  0.35646166 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "463.) tensor([0.]) \t [-1.56610693  1.35550962 -0.4745452  -0.47367361  0.1267638 ] \t True\n",
            "464.) tensor([0.]) \t [-0.36936484  1.43235947 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "465.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "466.) tensor([0.]) \t [ 0.82737724  0.66386103 -0.4745452  -0.47367361 -0.50647211] \t True\n",
            "467.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452  -0.47367361 -0.64842165] \t True\n",
            "468.) tensor([0.]) \t [-1.56610693  2.04715821 -0.4745452  -0.47367361 -0.11384571] \t True\n",
            "469.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.4928812 ] \t True\n",
            "470.) tensor([0.]) \t [ 0.82737724 -2.19879563  1.34013193  0.76762988 -0.26066181] \t False\n",
            "471.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50244517] \t True\n",
            "472.) tensor([0.]) \t [ 0.82737724  0.66386103 -0.4745452  -0.47367361 -0.47400493] \t True\n",
            "473.) tensor([0.]) \t [-0.36936484  0.27961182  0.43279337  2.00893337 -0.08968408] \t False\n",
            "474.) tensor([0.]) \t [-0.36936484 -0.48888662 -0.4745452  -0.47367361 -0.37073009] \t False\n",
            "475.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.45034667] \t True\n",
            "476.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361  0.39858208] \t True\n",
            "477.) tensor([0.]) \t [-0.36936484  0.35646166  0.43279337 -0.47367361 -0.22559322] \t True\n",
            "478.) tensor([0.]) \t [ 0.82737724 -0.02778756  0.43279337 -0.47367361 -0.50655667] \t True\n",
            "479.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.4969927 ] \t True\n",
            "480.) tensor([0.]) \t [ 0.82737724 -2.10273333 -0.4745452   0.76762988 -0.40101668] \t False\n",
            "481.) tensor([0.]) \t [ 0.82737724 -1.56478442  4.06214761  2.00893337  0.29589518] \t True\n",
            "482.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452  -0.47367361 -0.64842165] \t True\n",
            "483.) tensor([0.]) \t [ 0.82737724  1.58605915 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "484.) tensor([0.]) \t [ 0.82737724  2.58510712 -0.4745452  -0.47367361 -0.45538034] \t False\n",
            "485.) tensor([0.]) \t [-1.56610693 -0.33518693  0.43279337 -0.47367361  1.18542955] \t False\n",
            "486.) tensor([0.]) \t [ 0.82737724 -0.1046374   2.24747049  0.76762988 -0.13565762] \t True\n",
            "487.) tensor([0.]) \t [-1.56610693  0.4333115   0.43279337 -0.47367361  1.16370019] \t False\n",
            "488.) tensor([0.]) \t [-1.56610693  2.2008579  -0.4745452  -0.47367361 -0.05042144] \t True\n",
            "489.) tensor([0.]) \t [ 0.82737724  0.04906229 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "490.) tensor([0.]) \t [ 0.82737724 -1.56478442  0.43279337  0.76762988 -0.32828013] \t False\n",
            "491.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337 -0.47367361 -0.24639839] \t True\n",
            "492.) tensor([0.]) \t [ 0.82737724 -0.6425863  -0.4745452  -0.47367361 -0.50244517] \t True\n",
            "493.) tensor([0.]) \t [-1.56610693  1.97030837 -0.4745452  -0.47367361 -0.03431369] \t True\n",
            "494.) tensor([0.]) \t [-1.56610693  3.19990586 -0.4745452  -0.47367361  0.34832993] \t True\n",
            "495.) tensor([0.]) \t [ 0.82737724 -0.6425863  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "496.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.35730831] \t True\n",
            "497.) tensor([0.]) \t [-1.56610693  1.89345853  0.43279337 -0.47367361  0.92745387] \t False\n",
            "498.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.34438788] \t True\n",
            "499.) tensor([0.]) \t [-1.56610693 -0.33518693  0.43279337  2.00893337  2.40299019] \t True\n",
            "500.) tensor([0.]) \t [ 0.82737724 -0.41203677 -0.4745452  -0.47367361 -0.49145566] \t True\n",
            "501.) tensor([0.]) \t [ 0.82737724 -0.94998568 -0.4745452  -0.47367361 -0.47400493] \t True\n",
            "502.) tensor([0.]) \t [ 0.82737724 -0.6425863  -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "503.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.4948101 ] \t True\n",
            "504.) tensor([0.]) \t [ 0.82737724  0.58701119 -0.4745452  -0.47367361 -0.45538034] \t True\n",
            "505.) tensor([0.]) \t [-1.56610693 -1.02683552 -0.4745452  -0.47367361  1.09322879] \t False\n",
            "506.) tensor([0.]) \t [-1.56610693 -0.87313583  0.43279337 -0.47367361  1.54424578] \t True\n",
            "507.) tensor([0.]) \t [-0.36936484  0.27961182 -0.4745452   2.00893337 -0.12491979] \t False\n",
            "508.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361 -0.11384571] \t False\n",
            "509.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.19488782] \t True\n",
            "510.) tensor([0.]) \t [ 0.82737724 -0.25833709 -0.4745452  -0.47367361  0.48910361] \t False\n",
            "511.) tensor([0.]) \t [ 0.82737724 -0.02778756 -0.4745452  -0.47367361 -0.49237783] \t False\n",
            "512.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "513.) tensor([0.]) \t [-1.56610693  0.51016135 -0.4745452  -0.47367361 -0.11913106] \t False\n",
            "514.) tensor([0.]) \t [-1.56610693  1.89345853  0.43279337 -0.47367361  0.54757877] \t False\n",
            "515.) tensor([0.]) \t [ 0.82737724 -0.41203677 -0.4745452  -0.47367361 -0.49749607] \t True\n",
            "516.) tensor([0.]) \t [-1.56610693  1.35550962 -0.4745452  -0.47367361  0.03657651] \t True\n",
            "517.) tensor([0.]) \t [-0.36936484  0.35646166 -0.4745452  -0.47367361 -0.43700744] \t False\n",
            "518.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.16216896] \t True\n",
            "519.) tensor([0.]) \t [-0.36936484  0.51016135  0.43279337 -0.47367361 -0.12491979] \t False\n",
            "520.) tensor([0.]) \t [ 0.82737724  0.20276197 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "521.) tensor([0.]) \t [-1.56610693  0.04906229 -0.4745452  -0.47367361  1.2341716 ] \t False\n",
            "522.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "523.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50294854] \t True\n",
            "524.) tensor([0.]) \t [-1.56610693  1.12496009 -0.4745452   0.76762988  0.5189714 ] \t False\n",
            "525.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50286397] \t True\n",
            "526.) tensor([0.]) \t [ 0.82737724  0.85598564 -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "527.) tensor([0.]) \t [-0.36936484  1.58605915 -0.4745452  -0.47367361 -0.43700744] \t False\n",
            "528.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361  3.81703316] \t True\n",
            "529.) tensor([0.]) \t [ 0.82737724  0.74071088 -0.4745452  -0.47367361 -0.48885426] \t True\n",
            "530.) tensor([0.]) \t [-0.36936484 -0.48888662  1.34013193  0.76762988 -0.41687275] \t True\n",
            "531.) tensor([0.]) \t [-0.36936484 -2.10273333  0.43279337  0.76762988 -0.12491979] \t False\n",
            "532.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50286397] \t True\n",
            "533.) tensor([0.]) \t [ 0.82737724 -0.94998568  0.43279337  0.76762988 -0.50286397] \t True\n",
            "534.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452   2.00893337 -0.19824428] \t False\n",
            "535.) tensor([0.]) \t [ 0.82737724  0.04906229 -0.4745452  -0.47367361 -0.47400493] \t True\n",
            "536.) tensor([0.]) \t [-0.36936484 -1.71848411 -0.4745452   2.00893337 -0.11988611] \t False\n",
            "537.) tensor([0.]) \t [-1.56610693  1.20180994 -0.4745452  -0.47367361 -0.11384571] \t True\n",
            "538.) tensor([0.]) \t [-1.56610693  0.04906229 -0.4745452  -0.47367361  1.49441243] \t False\n",
            "539.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.35646869] \t True\n",
            "540.) tensor([0.]) \t [-1.56610693 -0.56573646 -0.4745452   2.00893337  0.34824536] \t False\n",
            "541.) tensor([0.]) \t [-1.56610693  0.51016135 -0.4745452   2.00893337  0.78114114] \t False\n",
            "542.) tensor([0.]) \t [ 0.82737724 -1.56478442  3.15480905  2.00893337 -0.01870931] \t True\n",
            "543.) tensor([0.]) \t [ 0.82737724 -1.41108474  3.15480905  2.00893337 -0.01870931] \t True\n",
            "544.) tensor([0.]) \t [-0.36936484  0.20276197  0.43279337 -0.47367361 -0.12491979] \t False\n",
            "545.) tensor([0.]) \t [-1.56610693  1.58605915  0.43279337 -0.47367361  1.49441243] \t True\n",
            "546.) tensor([0.]) \t [-1.56610693  2.66195696 -0.4745452  -0.47367361 -0.12491979] \t True\n",
            "547.) tensor([0.]) \t [-0.36936484 -0.79628599  0.43279337 -0.47367361 -0.12491979] \t False\n",
            "548.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452  -0.47367361 -0.36930455] \t False\n",
            "549.) tensor([0.]) \t [ 0.82737724  0.27961182  0.43279337  0.76762988 -0.2351572 ] \t True\n",
            "550.) tensor([0.]) \t [-0.36936484 -1.64163427  0.43279337  0.76762988  0.0915281 ] \t False\n",
            "551.) tensor([0.]) \t [-1.56610693 -0.94998568 -0.4745452   2.00893337  1.58417891] \t False\n",
            "552.) tensor([0.]) \t [-0.36936484 -0.18148724 -0.4745452  -0.47367361 -0.12491979] \t True\n",
            "553.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49078316] \t True\n",
            "554.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.50294854] \t False\n",
            "555.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.49187446] \t False\n",
            "556.) tensor([0.]) \t [-1.56610693  2.50825727 -0.4745452  -0.47367361 -0.11384571] \t True\n",
            "557.) tensor([0.]) \t [-1.56610693  1.43235947  0.43279337 -0.47367361  0.14891196] \t False\n",
            "558.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361  3.93272305] \t True\n",
            "559.) tensor([0.]) \t [-1.56610693  0.74071088  0.43279337  0.76762988  0.95530618] \t False\n",
            "560.) tensor([0.]) \t [ 0.82737724  0.51016135  0.43279337 -0.47367361 -0.2980781 ] \t False\n",
            "561.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "562.) tensor([0.]) \t [ 0.82737724  0.81756072 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "563.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452  -0.47367361 -0.37660338] \t True\n",
            "564.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "565.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "566.) tensor([0.]) \t [ 0.82737724 -0.41203677  1.34013193 -0.47367361 -0.16216896] \t True\n",
            "567.) tensor([0.]) \t [ 0.82737724 -0.79628599 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "568.) tensor([0.]) \t [ 0.82737724 -0.02778756 -0.4745452   4.49154034 -0.22408312] \t True\n",
            "569.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50286397] \t True\n",
            "570.) tensor([0.]) \t [ 0.82737724  0.20276197 -0.4745452  -0.47367361 -0.49027979] \t False\n",
            "571.) tensor([0.]) \t [-0.36936484  2.50825727 -0.4745452  -0.47367361 -0.43700744] \t False\n",
            "572.) tensor([0.]) \t [-1.56610693  1.81660868  1.34013193 -0.47367361  0.38809594] \t False\n",
            "573.) tensor([0.]) \t [-1.56610693  0.51016135 -0.4745452  -0.47367361 -0.1171176 ] \t False\n",
            "574.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t False\n",
            "575.) tensor([0.]) \t [ 0.82737724 -1.02683552 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "576.) tensor([0.]) \t [ 0.82737724 -0.79628599 -0.4745452  -0.47367361 -0.35646869] \t True\n",
            "577.) tensor([0.]) \t [-0.36936484  0.35646166 -0.4745452  -0.47367361 -0.38667072] \t False\n",
            "578.) tensor([0.]) \t [-1.56610693  0.74071088  0.43279337 -0.47367361  0.47710736] \t False\n",
            "579.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337 -0.47367361 -0.35730831] \t True\n",
            "580.) tensor([0.]) \t [ 0.82737724  0.20276197 -0.4745452  -0.47367361 -0.48885426] \t False\n",
            "581.) tensor([0.]) \t [-0.36936484 -0.33518693  0.43279337  0.76762988 -0.04438104] \t False\n",
            "582.) tensor([0.]) \t [-1.56610693  0.74071088  0.43279337  0.76762988  1.58417891] \t False\n",
            "583.) tensor([0.]) \t [-0.36936484  1.89345853 -0.4745452  -0.47367361 -0.12491979] \t True\n",
            "584.) tensor([0.]) \t [-1.56610693  0.51016135 -0.4745452  -0.47367361  0.15948267] \t True\n",
            "585.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.47299819] \t True\n",
            "586.) tensor([0.]) \t [-1.56610693 -0.87313583 -0.4745452   2.00893337  0.95530618] \t False\n",
            "587.) tensor([0.]) \t [-0.36936484  1.35550962 -0.4745452  -0.47367361 -0.34640135] \t True\n",
            "588.) tensor([0.]) \t [-1.56610693  2.35455759  0.43279337  0.76762988  0.94624557] \t False\n",
            "589.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "590.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "591.) tensor([0.]) \t [ 0.82737724  0.4333115  -0.4745452  -0.47367361 -0.50496201] \t True\n",
            "592.) tensor([0.]) \t [-1.56610693  1.73975884  0.43279337 -0.47367361  0.92745387] \t False\n",
            "593.) tensor([0.]) \t [ 0.82737724  1.35550962 -0.4745452  -0.47367361 -0.50244517] \t True\n",
            "594.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452   2.00893337 -0.49237783] \t True\n",
            "595.) tensor([0.]) \t [-0.36936484  0.58701119  0.43279337 -0.47367361 -0.12491979] \t True\n",
            "596.) tensor([0.]) \t [ 0.82737724  0.51016135  0.43279337  0.76762988 -0.16216896] \t True\n",
            "597.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452  -0.47367361  0.01602302] \t False\n",
            "598.) tensor([0.]) \t [ 0.82737724  1.50920931 -0.4745452  -0.47367361 -0.64842165] \t True\n",
            "599.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50294854] \t True\n",
            "600.) tensor([0.]) \t [-1.56610693  1.50920931  0.43279337 -0.47367361  0.49782998] \t False\n",
            "601.) tensor([0.]) \t [-0.36936484 -0.41203677  1.34013193  0.76762988 -0.1047851 ] \t False\n",
            "602.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "603.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361  0.20528908] \t True\n",
            "604.) tensor([0.]) \t [ 0.82737724  1.12496009 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "605.) tensor([0.]) \t [-1.56610693  0.4333115  -0.4745452  -0.47367361 -0.11384571] \t False\n",
            "606.) tensor([0.]) \t [ 0.82737724  0.51016135  0.43279337 -0.47367361 -0.33532727] \t True\n",
            "607.) tensor([0.]) \t [ 0.82737724  0.04906229 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "608.) tensor([0.]) \t [-1.56610693 -0.18148724 -0.4745452  -0.47367361 -0.03431369] \t False\n",
            "609.) tensor([0.]) \t [-0.36936484 -0.56573646  0.43279337  2.00893337  0.18876253] \t False\n",
            "610.) tensor([0.]) \t [-1.56610693  0.81756072 -0.4745452  -0.47367361  2.44149778] \t False\n",
            "611.) tensor([0.]) \t [ 0.82737724  0.74071088  0.43279337  5.73284383 -0.01870931] \t True\n",
            "612.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50647211] \t True\n",
            "613.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337 -0.47367361 -0.336334  ] \t False\n",
            "614.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "615.) tensor([0.]) \t [ 0.82737724  0.4333115  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "616.) tensor([0.]) \t [-0.36936484 -0.41203677  0.43279337  2.00893337  0.66033301] \t False\n",
            "617.) tensor([0.]) \t [ 0.82737724  0.35646166  0.43279337  0.76762988 -0.35848216] \t True\n",
            "618.) tensor([0.]) \t [ 0.82737724 -0.25833709  0.43279337 -0.47367361 -0.32425319] \t True\n",
            "619.) tensor([0.]) \t [-0.36936484 -1.94903364  1.34013193  0.76762988  0.13683115] \t False\n",
            "620.) tensor([0.]) \t [-0.36936484 -0.25833709 -0.4745452  -0.47367361 -0.43700744] \t True\n",
            "621.) tensor([0.]) \t [ 0.82737724 -0.18148724  0.43279337 -0.47367361 -0.35739086] \t True\n",
            "622.) tensor([0.]) \t [-1.56610693  0.97126041  0.43279337 -0.47367361  0.40974072] \t False\n",
            "623.) tensor([0.]) \t [ 0.82737724 -0.71943615  0.43279337  0.76762988 -0.33146745] \t False\n",
            "624.) tensor([0.]) \t [ 0.82737724 -0.6425863  -0.4745452  -0.47367361 -0.49027979] \t True\n",
            "625.) tensor([0.]) \t [ 0.82737724 -0.6425863  -0.4745452  -0.47367361 -0.32425319] \t True\n",
            "626.) tensor([0.]) \t [-1.56610693e+00  2.43140743e+00 -4.74545196e-01 -4.73673609e-01\n",
            "  2.34754408e-03] \t True\n",
            "627.) tensor([0.]) \t [-0.36936484  2.12400806 -0.4745452  -0.47367361 -0.39975827] \t True\n",
            "628.) tensor([0.]) \t [-1.56610693 -0.6425863  -0.4745452  -0.47367361  0.92124433] \t False\n",
            "629.) tensor([0.]) \t [ 0.82737724 -0.25833709 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "630.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49271408] \t True\n",
            "631.) tensor([0.]) \t [-1.56610693  3.89155445 -0.4745452  -0.47367361 -0.04438104] \t False\n",
            "632.) tensor([0.]) \t [ 0.82737724  1.662909   -0.4745452  -0.47367361 -0.50638754] \t True\n",
            "633.) tensor([0.]) \t [-1.56610693  0.20276197 -0.4745452  -0.47367361 -0.03431369] \t False\n",
            "634.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361 -0.64842165] \t True\n",
            "635.) tensor([0.]) \t [ 0.82737724 -1.56478442  2.24747049  2.00893337 -0.08666388] \t True\n",
            "636.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452  -0.47367361 -0.38667072] \t False\n",
            "637.) tensor([0.]) \t [ 0.82737724  0.20276197 -0.4745452  -0.47367361 -0.48885426] \t True\n",
            "638.) tensor([0.]) \t [-0.36936484  0.12591213  0.43279337  0.76762988 -0.11988611] \t True\n",
            "639.) tensor([0.]) \t [ 0.82737724  0.89441056 -0.4745452   5.73284383  0.15067374] \t True\n",
            "640.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337 -0.47367361 -0.32425319] \t True\n",
            "641.) tensor([0.]) \t [ 0.82737724 -0.71943615 -0.4745452  -0.47367361 -0.49027979] \t True\n",
            "642.) tensor([0.]) \t [-1.56610693 -0.41203677 -0.4745452  -0.47367361  0.74691217] \t False\n",
            "643.) tensor([0.]) \t [ 0.82737724 -2.10273333  2.24747049  2.00893337 -0.08666388] \t True\n",
            "644.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361  0.48910361] \t False\n",
            "645.) tensor([0.]) \t [ 0.82737724 -2.19879563  1.34013193  0.76762988 -0.26066181] \t False\n",
            "646.) tensor([0.]) \t [-1.56610693  1.43235947  0.43279337 -0.47367361  0.89649679] \t False\n",
            "647.) tensor([0.]) \t [ 0.82737724 -0.79628599 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "648.) tensor([0.]) \t [-1.56610693  2.04715821 -0.4745452  -0.47367361  0.06635974] \t False\n",
            "649.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49640477] \t True\n",
            "650.) tensor([0.]) \t [ 0.82737724 -0.48888662 -0.4745452  -0.47367361 -0.49640477] \t False\n",
            "651.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "652.) tensor([0.]) \t [-0.36936484 -0.87313583 -0.4745452   0.76762988 -0.18532385] \t False\n",
            "653.) tensor([0.]) \t [ 0.82737724 -0.6425863  -0.4745452  -0.47367361 -0.4786198 ] \t True\n",
            "654.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49078316] \t False\n",
            "655.) tensor([0.]) \t [ 0.82737724 -0.87313583 -0.4745452  -0.47367361 -0.51251252] \t True\n",
            "656.) tensor([0.]) \t [-0.36936484 -0.41203677  1.34013193 -0.47367361  0.83147785] \t True\n",
            "657.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "658.) tensor([0.]) \t [ 0.82737724  0.20276197  0.43279337  0.76762988 -0.336334  ] \t True\n",
            "659.) tensor([0.]) \t [-0.36936484 -0.48888662 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "660.) tensor([0.]) \t [-1.56610693  2.2008579  -0.4745452   2.00893337  1.63233504] \t True\n",
            "661.) tensor([0.]) \t [-1.56610693  1.58605915  1.34013193 -0.47367361  2.04257929] \t False\n",
            "662.) tensor([0.]) \t [ 0.82737724  0.81756072 -0.4745452  -0.47367361 -0.50294854] \t True\n",
            "663.) tensor([0.]) \t [-1.56610693  1.35550962 -0.4745452  -0.47367361 -0.13322535] \t True\n",
            "664.) tensor([0.]) \t [ 0.82737724  0.51016135 -0.4745452  -0.47367361 -0.49749607] \t True\n",
            "665.) tensor([0.]) \t [ 0.82737724 -0.71943615  0.43279337 -0.47367361 -0.48885426] \t False\n",
            "666.) tensor([0.]) \t [-0.36936484  0.20276197  1.34013193 -0.47367361  0.83147785] \t True\n",
            "667.) tensor([0.]) \t [-0.36936484 -0.33518693 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "668.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49187446] \t True\n",
            "669.) tensor([0.]) \t [ 0.82737724  1.04811025 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "670.) tensor([0.]) \t [-1.56610693 -0.1046374   0.43279337 -0.47367361  0.39858208] \t False\n",
            "671.) tensor([0.]) \t [-0.36936484  0.81756072  0.43279337  0.76762988  0.13683115] \t False\n",
            "672.) tensor([0.]) \t [-1.56610693  0.12591213  0.43279337 -0.47367361  0.39858208] \t True\n",
            "673.) tensor([0.]) \t [-0.36936484  3.12305602 -0.4745452  -0.47367361 -0.43700744] \t True\n",
            "674.) tensor([0.]) \t [-0.36936484  0.12591213 -0.4745452  -0.47367361 -0.38667072] \t False\n",
            "675.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452  -0.47367361 -0.64842165] \t True\n",
            "676.) tensor([0.]) \t [ 0.82737724 -0.87313583 -0.4745452  -0.47367361 -0.49187446] \t True\n",
            "677.) tensor([0.]) \t [ 0.82737724 -0.37361185 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "678.) tensor([0.]) \t [ 0.82737724 -0.87313583 -0.4745452  -0.47367361 -0.4502621 ] \t False\n",
            "679.) tensor([0.]) \t [0.82737724 1.04811025 0.43279337 6.97414732 0.29589518] \t True\n",
            "680.) tensor([0.]) \t [-1.56610693  0.51016135 -0.4745452   0.76762988  9.66716653] \t False\n",
            "681.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48457564] \t True\n",
            "682.) tensor([0.]) \t [-1.56610693 -0.18148724 -0.4745452  -0.47367361  0.89649679] \t False\n",
            "683.) tensor([0.]) \t [ 0.82737724 -0.71943615 -0.4745452  -0.47367361 -0.46267916] \t True\n",
            "684.) tensor([0.]) \t [ 0.82737724 -1.18053521  4.06214761  2.00893337  0.29589518] \t True\n",
            "685.) tensor([0.]) \t [-0.36936484  2.35455759  0.43279337  0.76762988  0.13683115] \t True\n",
            "686.) tensor([0.]) \t [-0.36936484 -0.33518693  0.43279337  2.00893337  0.18876253] \t True\n",
            "687.) tensor([0.]) \t [ 0.82737724 -1.18053521  3.15480905  0.76762988  0.15067374] \t True\n",
            "688.) tensor([0.]) \t [ 0.82737724 -0.79628599 -0.4745452  -0.47367361 -0.44363578] \t True\n",
            "689.) tensor([0.]) \t [ 0.82737724 -0.87313583 -0.4745452  -0.47367361 -0.49145566] \t True\n",
            "690.) tensor([0.]) \t [-1.56610693 -1.10368536 -0.4745452   0.76762988  3.6067928 ] \t False\n",
            "691.) tensor([0.]) \t [-1.56610693  0.12591213  0.43279337 -0.47367361  0.49925552] \t False\n",
            "692.) tensor([0.]) \t [ 0.82737724 -1.94903364 -0.4745452   0.76762988 -0.3782806 ] \t False\n",
            "693.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361  0.48910361] \t False\n",
            "694.) tensor([0.]) \t [ 0.82737724 -0.33518693 -0.4745452  -0.47367361 -0.50294854] \t True\n",
            "695.) tensor([0.]) \t [-1.56610693  2.35455759 -0.4745452  -0.47367361 -0.11384571] \t True\n",
            "696.) tensor([0.]) \t [-0.36936484  1.73975884 -0.4745452  -0.47367361 -0.37660338] \t True\n",
            "697.) tensor([0.]) \t [ 0.82737724  1.12496009 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "698.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49271408] \t False\n",
            "699.) tensor([0.]) \t [-1.56610693  1.50920931  0.43279337  0.76762988  1.58417891] \t True\n",
            "700.) tensor([0.]) \t [ 0.82737724  0.97126041 -0.4745452  -0.47367361 -0.4943913 ] \t True\n",
            "701.) tensor([0.]) \t [-1.56610693 -0.87313583  0.43279337 -0.47367361  3.93272305] \t False\n",
            "702.) tensor([0.]) \t [-1.56610693  0.4333115  -0.4745452  -0.47367361 -0.11913106] \t False\n",
            "703.) tensor([0.]) \t [ 0.82737724 -0.87313583 -0.4745452   0.76762988 -0.35739086] \t True\n",
            "704.) tensor([0.]) \t [ 0.82737724 -0.33518693 -0.4745452  -0.47367361 -0.49254495] \t True\n",
            "705.) tensor([0.]) \t [ 0.82737724 -0.25833709  0.43279337 -0.47367361 -0.49027979] \t True\n",
            "706.) tensor([0.]) \t [-0.36936484  0.74071088 -0.4745452  -0.47367361 -0.12491979] \t True\n",
            "707.) tensor([0.]) \t [-0.36936484  1.20180994 -0.4745452  -0.47367361 -0.37660338] \t False\n",
            "708.) tensor([0.]) \t [-1.56610693  0.97126041 -0.4745452  -0.47367361 -0.11913106] \t False\n",
            "709.) tensor([0.]) \t [-1.56610693 -0.56573646 -0.4745452  -0.47367361  2.40299019] \t False\n",
            "710.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337  0.76762988 -0.34145224] \t False\n",
            "711.) tensor([0.]) \t [-1.56610693 -0.41203677 -0.4745452  -0.47367361  0.34832993] \t False\n",
            "712.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361 -0.11384571] \t True\n",
            "713.) tensor([0.]) \t [-1.56610693  1.43235947  0.43279337 -0.47367361  0.39858208] \t False\n",
            "714.) tensor([0.]) \t [ 0.82737724 -0.02778756 -0.4745452  -0.47367361 -0.45747837] \t True\n",
            "715.) tensor([0.]) \t [-0.36936484  1.73975884 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "716.) tensor([0.]) \t [ 0.82737724 -0.79628599 -0.4745452  -0.47367361 -0.4943913 ] \t True\n",
            "717.) tensor([0.]) \t [-1.56610693  0.66386103 -0.4745452  -0.47367361  3.93272305] \t False\n",
            "718.) tensor([0.]) \t [-0.36936484 -0.18148724 -0.4745452  -0.47367361 -0.43700744] \t False\n",
            "719.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.336334  ] \t True\n",
            "720.) tensor([0.]) \t [ 0.82737724  0.27961182 -0.4745452  -0.47367361 -0.49187446] \t True\n",
            "721.) tensor([0.]) \t [-0.36936484 -1.79533395 -0.4745452   0.76762988  0.01602302] \t False\n",
            "722.) tensor([0.]) \t [ 0.82737724 -0.94998568  0.43279337 -0.47367361 -0.50638754] \t True\n",
            "723.) tensor([0.]) \t [-0.36936484  0.35646166 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "724.) tensor([0.]) \t [-0.36936484  1.58605915 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "725.) tensor([0.]) \t [-1.56610693 -0.18148724  0.43279337 -0.47367361  0.42073024] \t False\n",
            "726.) tensor([0.]) \t [ 0.82737724 -0.71943615 -0.4745452  -0.47367361 -0.47400493] \t True\n",
            "727.) tensor([0.]) \t [-0.36936484  0.04906229  2.24747049 -0.47367361 -0.22559322] \t False\n",
            "728.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49262951] \t False\n",
            "729.) tensor([0.]) \t [-0.36936484 -0.33518693  0.43279337 -0.47367361 -0.12491979] \t True\n",
            "730.) tensor([0.]) \t [ 0.82737724 -0.33518693  0.43279337 -0.47367361 -0.48885426] \t True\n",
            "731.) tensor([0.]) \t [-1.56610693 -0.02778756 -0.4745452  -0.47367361  3.6067928 ] \t False\n",
            "732.) tensor([0.]) \t [ 0.82737724 -1.41108474 -0.4745452  -0.47367361 -0.27014122] \t True\n",
            "733.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452  -0.47367361 -0.64842165] \t True\n",
            "734.) tensor([0.]) \t [-0.36936484 -0.48888662 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "735.) tensor([0.]) \t [-0.36936484 -0.48888662 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "736.) tensor([0.]) \t [ 0.82737724 -0.06621248 -0.4745452  -0.47367361 -0.32425319] \t True\n",
            "737.) tensor([0.]) \t [0.82737724 1.43235947 0.43279337 3.25023685 0.04370822] \t True\n",
            "738.) tensor([0.]) \t [-1.56610693  0.4333115  -0.4745452  -0.47367361  9.66716653] \t False\n",
            "739.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "740.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "741.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361 -0.04438104] \t False\n",
            "742.) tensor([0.]) \t [-1.56610693  0.51016135  0.43279337 -0.47367361  0.93919843] \t True\n",
            "743.) tensor([0.]) \t [-1.56610693 -0.6425863   1.34013193  2.00893337  4.6344169 ] \t False\n",
            "744.) tensor([0.]) \t [ 0.82737724 -0.41203677  0.43279337 -0.47367361 -0.32425319] \t True\n",
            "745.) tensor([0.]) \t [ 0.82737724  0.12591213 -0.4745452  -0.47367361 -0.48885426] \t False\n",
            "746.) tensor([0.]) \t [-1.56610693  3.12305602  0.43279337  0.76762988  0.78114114] \t True\n",
            "747.) tensor([0.]) \t [ 0.82737724 -1.02683552  0.43279337  0.76762988 -0.24069424] \t True\n",
            "748.) tensor([0.]) \t [-0.36936484  0.04906229 -0.4745452  -0.47367361 -0.38667072] \t False\n",
            "749.) tensor([0.]) \t [-1.56610693 -0.79628599  0.43279337 -0.47367361  0.42073024] \t True\n",
            "750.) tensor([0.]) \t [ 0.82737724  0.12591213 -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "751.) tensor([0.]) \t [-0.36936484 -1.94903364  0.43279337  0.76762988 -0.18532385] \t False\n",
            "752.) tensor([0.]) \t [ 0.82737724 -1.79533395 -0.4745452   0.76762988 -0.39724143] \t False\n",
            "753.) tensor([0.]) \t [ 0.82737724  0.27961182 -0.4745452  -0.47367361 -0.45714213] \t True\n",
            "754.) tensor([0.]) \t [ 0.82737724 -0.48888662 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "755.) tensor([0.]) \t [-0.36936484  1.43235947  0.43279337  2.00893337  0.66033301] \t False\n",
            "756.) tensor([0.]) \t [-0.36936484 -2.20494362  0.43279337  0.76762988 -0.35646869] \t False\n",
            "757.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49145566] \t True\n",
            "758.) tensor([0.]) \t [-0.36936484 -0.87313583 -0.4745452  -0.47367361 -0.41687275] \t True\n",
            "759.) tensor([0.]) \t [ 0.82737724  0.35646166 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "760.) tensor([0.]) \t [-1.56610693  0.27961182 -0.4745452  -0.47367361  1.09322879] \t False\n",
            "761.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.35646869] \t True\n",
            "762.) tensor([0.]) \t [ 0.82737724  0.89441056 -0.4745452  -0.47367361 -0.50496201] \t True\n",
            "763.) tensor([0.]) \t [ 0.82737724 -0.71943615 -0.4745452  -0.47367361 -0.50286397] \t False\n",
            "764.) tensor([0.]) \t [-1.56610693  0.51016135  0.43279337  2.00893337  1.76774081] \t False\n",
            "765.) tensor([0.]) \t [ 0.82737724 -1.02683552 -0.4745452  -0.47367361 -0.49187446] \t True\n",
            "766.) tensor([0.]) \t [-1.56610693  1.662909    0.43279337 -0.47367361  0.92124433] \t False\n",
            "767.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361  0.14891196] \t True\n",
            "768.) tensor([0.]) \t [ 0.82737724  0.08748721 -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "769.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337 -0.47367361 -0.16216896] \t True\n",
            "770.) tensor([0.]) \t [ 0.82737724  0.20276197 -0.4745452  -0.47367361 -0.48004533] \t True\n",
            "771.) tensor([0.]) \t [ 0.82737724 -0.41203677 -0.4745452  -0.47367361 -0.45714213] \t True\n",
            "772.) tensor([0.]) \t [ 0.82737724  1.43235947 -0.4745452  -0.47367361 -0.49027979] \t True\n",
            "773.) tensor([0.]) \t [-0.36936484  2.12400806 -0.4745452  -0.47367361 -0.43700744] \t True\n",
            "774.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50294854] \t True\n",
            "775.) tensor([0.]) \t [-0.36936484  1.89345853  0.43279337  3.25023685 -0.18532385] \t False\n",
            "776.) tensor([0.]) \t [ 0.82737724 -0.87313583 -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "777.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "778.) tensor([0.]) \t [ 0.82737724 -1.8721838  -0.4745452  -0.47367361 -0.39724143] \t False\n",
            "779.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49262951] \t True\n",
            "780.) tensor([0.]) \t [-1.56610693  1.04811025 -0.4745452   0.76762988  3.6067928 ] \t False\n",
            "781.) tensor([0.]) \t [ 0.82737724 -1.25738505 -0.4745452  -0.47367361 -0.50286397] \t False\n",
            "782.) tensor([0.]) \t [-1.56610693 -0.94998568  0.43279337 -0.47367361  0.49925552] \t False\n",
            "783.) tensor([0.]) \t [-1.56610693 -0.02778756 -0.4745452  -0.47367361 -0.04438104] \t True\n",
            "784.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337  2.00893337 -0.17626324] \t True\n",
            "785.) tensor([0.]) \t [ 0.82737724 -0.33518693 -0.4745452  -0.47367361 -0.50647211] \t True\n",
            "786.) tensor([0.]) \t [ 0.82737724 -0.33518693 -0.4745452  -0.47367361 -0.50244517] \t True\n",
            "787.) tensor([0.]) \t [ 0.82737724 -0.87313583 -0.4745452  -0.47367361 -0.49749607] \t False\n",
            "788.) tensor([0.]) \t [ 0.82737724 -1.64163427  3.15480905  0.76762988 -0.06199889] \t True\n",
            "789.) tensor([0.]) \t [ 0.82737724 -2.17958317  0.43279337  2.00893337 -0.23415046] \t False\n",
            "790.) tensor([0.]) \t [-1.56610693  1.27865978 -0.4745452  -0.47367361  0.94624557] \t True\n",
            "791.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "792.) tensor([0.]) \t [-0.36936484 -1.02683552 -0.4745452  -0.47367361 -0.12491979] \t True\n",
            "793.) tensor([0.]) \t [ 0.82737724 -0.1046374   6.7841633   2.00893337  0.75194584] \t True\n",
            "794.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361 -0.03037132] \t True\n",
            "795.) tensor([0.]) \t [ 0.82737724 -0.33518693 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "796.) tensor([0.]) \t [-0.36936484  0.74071088 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "797.) tensor([0.]) \t [-1.56610693  1.50920931 -0.4745452  -0.47367361 -0.12634532] \t False\n",
            "798.) tensor([0.]) \t [ 0.82737724  0.12591213 -0.4745452  -0.47367361 -0.47358612] \t False\n",
            "799.) tensor([0.]) \t [ 0.82737724  0.04906229 -0.4745452  -0.47367361 -0.50286397] \t True\n",
            "800.) tensor([0.]) \t [ 0.82737724  0.04906229  0.43279337  0.76762988 -0.16216896] \t True\n",
            "801.) tensor([0.]) \t [-0.36936484  0.35646166 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "802.) tensor([0.]) \t [-0.36936484  0.12591213  0.43279337  0.76762988 -0.11988611] \t False\n",
            "803.) tensor([0.]) \t [-1.56610693 -1.41108474  0.43279337  2.00893337  1.76774081] \t False\n",
            "804.) tensor([0.]) \t [ 0.82737724 -2.22415608 -0.4745452   0.76762988 -0.47694056] \t False\n",
            "805.) tensor([0.]) \t [ 0.82737724 -0.18148724 -0.4745452  -0.47367361 -0.50798221] \t False\n",
            "806.) tensor([0.]) \t [ 0.82737724  0.12591213 -0.4745452  -0.47367361 -0.49187446] \t True\n",
            "807.) tensor([0.]) \t [-1.56610693  0.74071088 -0.4745452  -0.47367361 -0.64842165] \t True\n",
            "808.) tensor([0.]) \t [ 0.82737724 -0.87313583 -0.4745452  -0.47367361 -0.49187446] \t True\n",
            "809.) tensor([0.]) \t [-0.36936484  0.74071088 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "810.) tensor([0.]) \t [-1.56610693  0.27961182  0.43279337 -0.47367361  0.42073024] \t False\n",
            "811.) tensor([0.]) \t [ 0.82737724 -0.25833709 -0.4745452  -0.47367361 -0.48960931] \t True\n",
            "812.) tensor([0.]) \t [ 0.82737724  0.74071088 -0.4745452  -0.47367361 -0.16216896] \t True\n",
            "813.) tensor([0.]) \t [-0.36936484  0.4333115  -0.4745452  -0.47367361 -0.43700744] \t True\n",
            "814.) tensor([0.]) \t [ 0.82737724 -1.79533395  3.15480905  2.00893337 -0.01870931] \t True\n",
            "815.) tensor([0.]) \t [ 0.82737724  0.08748721 -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "816.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361 -0.64842165] \t True\n",
            "817.) tensor([0.]) \t [ 0.82737724 -0.48888662 -0.4745452  -0.47367361 -0.48885426] \t True\n",
            "818.) tensor([0.]) \t [-0.36936484  0.12591213  0.43279337  0.76762988  0.09664634] \t True\n",
            "819.) tensor([0.]) \t [ 0.82737724  1.04811025 -0.4745452  -0.47367361 -0.51855292] \t True\n",
            "820.) tensor([0.]) \t [ 0.82737724 -1.48793458  2.24747049  2.00893337 -0.08666388] \t True\n",
            "821.) tensor([0.]) \t [-1.56610693  1.73975884  0.43279337  0.76762988  1.2341716 ] \t False\n",
            "822.) tensor([0.]) \t [ 0.82737724 -0.18148724 -0.4745452  -0.47367361 -0.47400493] \t False\n",
            "823.) tensor([0.]) \t [-1.56610693  0.66386103 -0.4745452  -0.47367361 -0.64842165] \t True\n",
            "824.) tensor([0.]) \t [ 0.82737724 -0.18148724 -0.4745452   0.76762988 -0.39724143] \t False\n",
            "825.) tensor([0.]) \t [ 0.82737724 -2.10273333  3.15480905  0.76762988  0.15067374] \t True\n",
            "826.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50848558] \t True\n",
            "827.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361  0.48910361] \t True\n",
            "828.) tensor([0.]) \t [-0.36936484 -2.17958317 -0.4745452   2.00893337  0.09664634] \t False\n",
            "829.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.49237783] \t False\n",
            "830.) tensor([0.]) \t [-1.56610693  2.50825727 -0.4745452  -0.47367361  0.96235332] \t False\n",
            "831.) tensor([0.]) \t [ 0.82737724 -1.10368536  0.43279337 -0.47367361 -0.35739086] \t False\n",
            "832.) tensor([0.]) \t [-0.36936484 -2.19264764  0.43279337  0.76762988 -0.27089627] \t False\n",
            "833.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50286397] \t True\n",
            "834.) tensor([0.]) \t [ 0.82737724 -0.48888662 -0.4745452  -0.47367361 -0.49027979] \t True\n",
            "835.) tensor([0.]) \t [ 0.82737724 -0.87313583 -0.4745452  -0.47367361 -0.48130375] \t True\n",
            "836.) tensor([0.]) \t [-1.56610693  0.74071088  0.43279337  0.76762988  1.0259447 ] \t False\n",
            "837.) tensor([0.]) \t [ 0.82737724 -0.6425863  -0.4745452  -0.47367361 -0.47400493] \t True\n",
            "838.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48633742] \t True\n",
            "839.) tensor([0.]) \t [ 0.82737724  0.20276197 -0.4745452  -0.47367361  0.48910361] \t False\n",
            "840.) tensor([0.]) \t [-1.56610693 -0.1046374  -0.4745452  -0.47367361 -0.05042144] \t False\n",
            "841.) tensor([0.]) \t [ 0.82737724 -0.71943615 -0.4745452  -0.47367361 -0.48885426] \t True\n",
            "842.) tensor([0.]) \t [-0.36936484 -1.02683552 -0.4745452  -0.47367361 -0.43700744] \t True\n",
            "843.) tensor([0.]) \t [-1.56610693  0.04906229 -0.4745452  -0.47367361 -0.02424635] \t False\n",
            "844.) tensor([0.]) \t [ 0.82737724  0.39488658 -0.4745452  -0.47367361 -0.5188046 ] \t True\n",
            "845.) tensor([0.]) \t [ 0.82737724 -0.94998568 -0.4745452  -0.47367361 -0.47400493] \t True\n",
            "846.) tensor([0.]) \t [ 0.82737724  0.97126041 -0.4745452  -0.47367361 -0.49640477] \t True\n",
            "847.) tensor([0.]) \t [ 0.82737724 -0.1046374   6.7841633   2.00893337  0.75194584] \t True\n",
            "848.) tensor([0.]) \t [ 0.82737724  0.4333115  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "849.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452   0.76762988  0.01602302] \t True\n",
            "850.) tensor([0.]) \t [-1.56610693 -0.1046374   0.43279337 -0.47367361  1.14566354] \t False\n",
            "851.) tensor([0.]) \t [ 0.82737724 -1.94903364  3.15480905  2.00893337 -0.01870931] \t True\n",
            "852.) tensor([0.]) \t [ 0.82737724  3.43045539 -0.4745452  -0.47367361 -0.49187446] \t True\n",
            "853.) tensor([0.]) \t [ 0.82737724 -1.56478442  0.43279337  0.76762988 -0.34145224] \t True\n",
            "854.) tensor([0.]) \t [-1.56610693 -1.02683552 -0.4745452   0.76762988  0.14488502] \t False\n",
            "855.) tensor([0.]) \t [-0.36936484  1.12496009  0.43279337 -0.47367361 -0.12491979] \t True\n",
            "856.) tensor([0.]) \t [ 0.82737724 -0.87313583 -0.4745452   0.76762988 -0.46016233] \t False\n",
            "857.) tensor([0.]) \t [-1.56610693  1.20180994  0.43279337  0.76762988  2.67111778] \t False\n",
            "858.) tensor([0.]) \t [-1.56610693  1.662909   -0.4745452  -0.47367361 -0.11384571] \t False\n",
            "859.) tensor([0.]) \t [ 0.82737724 -0.41203677 -0.4745452   3.25023685 -0.26066181] \t False\n",
            "860.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.50286397] \t True\n",
            "861.) tensor([0.]) \t [ 0.82737724  0.89441056  1.34013193 -0.47367361 -0.36435545] \t True\n",
            "862.) tensor([0.]) \t [-0.36936484 -0.6425863   0.43279337 -0.47367361 -0.41687275] \t True\n",
            "863.) tensor([0.]) \t [-1.56610693  1.43235947 -0.4745452  -0.47367361 -0.12634532] \t False\n",
            "864.) tensor([0.]) \t [ 0.82737724 -0.1046374   6.7841633   2.00893337  0.75194584] \t True\n",
            "865.) tensor([0.]) \t [-0.36936484 -0.41203677 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "866.) tensor([0.]) \t [-0.36936484  0.97126041 -0.4745452  -0.47367361 -0.38667072] \t False\n",
            "867.) tensor([0.]) \t [-0.36936484 -0.18148724  0.43279337 -0.47367361 -0.36938912] \t False\n",
            "868.) tensor([0.]) \t [-1.56610693  0.12591213 -0.4745452  -0.47367361  0.36829548] \t True\n",
            "869.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.45714213] \t True\n",
            "870.) tensor([0.]) \t [ 0.82737724 -1.94903364  0.43279337  0.76762988 -0.42425614] \t False\n",
            "871.) tensor([0.]) \t [ 0.82737724 -0.25833709 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "872.) tensor([0.]) \t [-1.56610693  1.35550962  0.43279337  0.76762988  0.40974072] \t False\n",
            "873.) tensor([0.]) \t [-1.56610693  0.27961182 -0.4745452  -0.47367361 -0.54774822] \t True\n",
            "874.) tensor([0.]) \t [ 0.82737724  1.35550962 -0.4745452  -0.47367361 -0.46720947] \t True\n",
            "875.) tensor([0.]) \t [-0.36936484 -0.1046374   0.43279337 -0.47367361 -0.16518916] \t False\n",
            "876.) tensor([0.]) \t [ 0.82737724 -1.10368536 -0.4745452  -0.47367361 -0.50294854] \t False\n",
            "877.) tensor([0.]) \t [ 0.82737724 -0.71943615 -0.4745452  -0.47367361 -0.45017955] \t True\n",
            "878.) tensor([0.]) \t [ 0.82737724 -0.79628599 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "879.) tensor([0.]) \t [ 0.82737724 -0.1046374  -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "880.) tensor([0.]) \t [-1.56610693  2.04715821 -0.4745452   0.76762988  1.0259447 ] \t False\n",
            "881.) tensor([0.]) \t [-0.36936484 -0.33518693 -0.4745452   0.76762988 -0.12491979] \t False\n",
            "882.) tensor([0.]) \t [ 0.82737724  0.27961182 -0.4745452  -0.47367361 -0.48944219] \t True\n",
            "883.) tensor([0.]) \t [ 0.82737724 -0.56573646 -0.4745452  -0.47367361 -0.43667119] \t True\n",
            "884.) tensor([0.]) \t [-0.36936484 -0.1046374  -0.4745452  -0.47367361 -0.43700744] \t True\n",
            "885.) tensor([0.]) \t [ 0.82737724 -0.33518693 -0.4745452  -0.47367361 -0.50647211] \t True\n",
            "886.) tensor([0.]) \t [ 0.82737724  0.74071088 -0.4745452   5.73284383 -0.06199889] \t True\n",
            "887.) tensor([0.]) \t [-0.36936484 -0.18148724 -0.4745452  -0.47367361 -0.38667072] \t True\n",
            "888.) tensor([0.]) \t [-1.56610693 -0.79628599 -0.4745452  -0.47367361 -0.04438104] \t False\n",
            "889.) tensor([0.]) \t [ 0.82737724 -0.1046374   0.43279337  2.00893337 -0.17626324] \t True\n",
            "890.) tensor([0.]) \t [-1.56610693 -0.25833709 -0.4745452  -0.47367361 -0.04438104] \t False\n",
            "891.) tensor([0.]) \t [ 0.82737724  0.20276197 -0.4745452  -0.47367361 -0.49237783] \t True\n",
            "we goat 549 correct out of  891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': test_predictions})\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission.csv' created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28AvP2xqQxed",
        "outputId": "5323b8e1-60ca-4145-b8e5-0b641a6aba39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file 'submission.csv' created successfully!\n"
          ]
        }
      ]
    }
  ]
}